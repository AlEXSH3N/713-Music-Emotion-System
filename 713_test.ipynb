{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import optuna\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_tuner import RandomSearch, HyperParameters, Objective\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, Bidirectional, LSTM, Layer\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, Callback\n",
    "from transformers import BertTokenizer, TFBertModel, BertModel, get_linear_schedule_with_warmup, WarmUp, AdamW, RobertaTokenizer, TFRobertaModel, RobertaModel, XLMRobertaTokenizer, XLMRobertaModel, AutoTokenizer, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解压 cleaned_lyrics.zip 文件\n",
    "with zipfile.ZipFile('sampled.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('sampled')\n",
    "\n",
    "# 获取所有歌词文件的路径\n",
    "lyrics_files = {os.path.splitext(f)[0]: os.path.join('sampled', f) for f in os.listdir('sampled')}\n",
    "\n",
    "# 读取 filtered_dataset.csv 文件\n",
    "data = pd.read_csv('sampled_dataset.csv')\n",
    "\n",
    "def read_lyrics(record_id):\n",
    "    file_path = lyrics_files.get(str(record_id))\n",
    "    if file_path and os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    return ''\n",
    "\n",
    "# 读取歌词并添加到数据框中\n",
    "data['lyrics'] = data['record_id'].apply(read_lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Tokenizer 处理文本\n",
    "max_words = 5000\n",
    "max_len = 128\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['lyrics'])\n",
    "sequences = tokenizer.texts_to_sequences(data['lyrics'])\n",
    "X_lyrics = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# 准备标签\n",
    "y_valence = to_categorical(data['valence_bin'].values)\n",
    "y_energy = to_categorical(data['energy_bin'].values)\n",
    "y_danceability = to_categorical(data['danceability_bin'].values)\n",
    "\n",
    "# 拆分数据集\n",
    "X_train_val, X_test, y_train_val_valence, y_test_valence, y_train_val_energy, y_test_energy, y_train_val_danceability, y_test_danceability = train_test_split(\n",
    "    X_lyrics, y_valence, y_energy, y_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train_valence, y_val_valence, y_train_energy, y_val_energy, y_train_danceability, y_val_danceability = train_test_split(\n",
    "    X_train_val, y_train_val_valence, y_train_val_energy, y_train_val_danceability, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len = X_train.shape[1]\n",
    "# max_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# inputs = Input(shape=(max_len,))\n",
    "\n",
    "# x = Embedding(input_dim=max_words, output_dim=128, input_length=max_len)(inputs)\n",
    "\n",
    "# x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "\n",
    "# x = Bidirectional(LSTM(32))(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "\n",
    "# outputs = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch, HyperParameters, Objective\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# 构建模型函数\n",
    "def build_model(hp):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=hp.Int('input_dim', min_value=1000, max_value=10000, step=1000),\n",
    "                  output_dim=hp.Int('output_dim', min_value=32, max_value=128, step=32))(inputs)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=5, step=1)\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            x = Dense(units=hp.Int(f'units_layer{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        else:\n",
    "            x = Dense(units=hp.Int(f'units_layer{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        x = Dropout(rate=hp.Float(f'dropout_layer{i+1}', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
    "\n",
    "    x = Dense(units=hp.Int('units_final', min_value=32, max_value=512, step=32),\n",
    "              activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(hp.Choice('l2_regularization', values=[0.0, 1e-4, 1e-3])),\n",
    "              kernel_initializer=hp.Choice('kernel_initializer', values=['glorot_uniform', 'he_normal']))(x)\n",
    "\n",
    "    \n",
    "    output_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(x)\n",
    "    output_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(x)\n",
    "    output_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[output_valence, output_energy, output_danceability])\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# 超参数调优\n",
    "dnn_tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=Objective('val_valence_output_accuracy', direction='max'),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='dnn_mood_detection_600'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 01s]\n",
      "\n",
      "Best val_valence_output_accuracy So Far: 0.5520833134651184\n",
      "Total elapsed time: 00h 00m 22s\n",
      "{'input_dim': 9000, 'output_dim': 96, 'num_layers': 5, 'units_layer1': 96, 'dropout_layer1': 0.2, 'units_final': 384, 'l2_regularization': 0.0, 'kernel_initializer': 'glorot_uniform', 'optimizer': 'adam', 'learning_rate': 0.001, 'units_layer2': 32, 'dropout_layer2': 0.0, 'units_layer3': 32, 'dropout_layer3': 0.0, 'units_layer4': 32, 'dropout_layer4': 0.0, 'units_layer5': 32, 'dropout_layer5': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 40 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# 启动调优过程\n",
    "dnn_tuner.search(X_train, [y_train_valence, y_train_energy, y_train_danceability], \n",
    "             epochs=20,\n",
    "             validation_data=(X_val, [y_val_valence, y_val_energy, y_val_danceability]), \n",
    "             callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# 获取最佳模型\n",
    "\n",
    "best_model_DNN = dnn_tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters_DNN = dnn_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters_DNN.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 评估模型\n",
    "\n",
    "# loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "# print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = best_model_DNN.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "#print(f'Test Loss: {loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_LSTM(hp):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    \n",
    "    x = Embedding(input_dim=hp.Int('input_dim', min_value=5000, max_value=20000, step=1000),\n",
    "                output_dim=hp.Int('output_dim', min_value=64, max_value=256, step=32))(inputs)\n",
    "\n",
    "    for _ in range(hp.Int('num_lstm_layers', 1, 2)):\n",
    "        x = Bidirectional(LSTM(units=hp.Int('units_lstm', min_value=64, max_value=256, step=32),\n",
    "                            return_sequences=True))(x)\n",
    "        x = Dropout(rate=hp.Float('dropout_lstm', min_value=0.1, max_value=0.3, step=0.1))(x)\n",
    "\n",
    "    x = Bidirectional(LSTM(units=hp.Int('units_lstm', min_value=64, max_value=256, step=32),\n",
    "                        return_sequences=False))(x)\n",
    "    x = Dropout(rate=hp.Float('dropout_lstm', min_value=0.1, max_value=0.3, step=0.1))(x)\n",
    "\n",
    "    x = Dense(units=hp.Int('units_dense', min_value=64, max_value=256, step=32), activation='relu')(x)\n",
    "    x = Dropout(rate=hp.Float('dropout_dense', min_value=0.1, max_value=0.3, step=0.1))(x)\n",
    "    \n",
    "    output_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(x)\n",
    "    output_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(x)\n",
    "    output_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[output_valence, output_energy, output_danceability])\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 14s]\n",
      "val_valence_output_accuracy: 0.4479166567325592\n",
      "\n",
      "Best val_valence_output_accuracy So Far: 0.5\n",
      "Total elapsed time: 00h 06m 40s\n"
     ]
    }
   ],
   "source": [
    "tuner_LSTM = RandomSearch(\n",
    "    build_model_LSTM,\n",
    "    objective=Objective('val_valence_output_accuracy', direction='max'),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='bi_lstm_mood_detection'\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Launch the search\n",
    "tuner_LSTM.search(X_train, [y_train_valence, y_train_energy, y_train_danceability], \n",
    "             epochs=20, \n",
    "             validation_data=(X_val, [y_val_valence, y_val_energy, y_val_danceability]), \n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 56 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">985,088</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">114,912</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ valence_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">675</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ energy_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">675</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ danceability_output │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">675</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m224\u001b[0m)  │  \u001b[38;5;34m1,568,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │    \u001b[38;5;34m985,088\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │  \u001b[38;5;34m1,574,912\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m1,574,912\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)       │    \u001b[38;5;34m114,912\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ valence_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m675\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ energy_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m675\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ danceability_output │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m675\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,819,849</span> (22.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,819,849\u001b[0m (22.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,819,849</span> (22.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,819,849\u001b[0m (22.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 300ms/step - danceability_output_accuracy: 0.4388 - energy_output_accuracy: 0.2552 - loss: 3.3616 - valence_output_accuracy: 0.4609\n",
      "Validation Loss and Accuracy: [3.2785587310791016, 0.4479166567325592, 0.2916666567325592, 0.5]\n"
     ]
    }
   ],
   "source": [
    "best_model_LSTM = tuner_LSTM.get_best_models(num_models=1)[0]\n",
    "best_model_LSTM.summary()\n",
    "\n",
    "# Evaluate the best model\n",
    "results = best_model_LSTM.evaluate(X_val, [y_val_valence, y_val_energy, y_val_danceability])\n",
    "print(\"Validation Loss and Accuracy:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 02s]\n",
      "val_valence_output_accuracy: 0.3645833432674408\n",
      "\n",
      "Best val_valence_output_accuracy So Far: 0.5625\n",
      "Total elapsed time: 00h 00m 28s\n",
      "{'embedding_output_dim': 96, 'filters': 96, 'kernel_size': 7, 'pool_size': 5, 'num_layers': 3, 'dense_units_1': 288, 'dropout_1': 0.0, 'optimizer': 'rmsprop', 'learning_rate': 0.001, 'dense_units_2': 224, 'dropout_2': 0.30000000000000004, 'dense_units_3': 32, 'dropout_3': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 17 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# 构建 CNN 模型函数\n",
    "def build_cnn_model(hp):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=max_words, output_dim=hp.Int('embedding_output_dim', min_value=32, max_value=128, step=32), input_length=max_len)(inputs)\n",
    "    x = tf.keras.layers.Conv1D(filters=hp.Int('filters', min_value=32, max_value=128, step=32), kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=2), activation='relu')(x)\n",
    "    x = tf.keras.layers.AveragePooling1D(pool_size=hp.Int('pool_size', min_value=2, max_value=5, step=1))(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
    "    for i in range(num_layers):\n",
    "        x = Dense(units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        x = Dropout(rate=hp.Float(f'dropout_{i+1}', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    output_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(x)\n",
    "    output_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(x)\n",
    "    output_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[output_valence, output_energy, output_danceability])\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# 超参数调优\n",
    "tuner_CNN = RandomSearch(\n",
    "    build_cnn_model,\n",
    "    objective=Objective('val_valence_output_accuracy', direction='max'),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='cnn_mood_detection_600'\n",
    ")\n",
    "\n",
    "# 启动调优过程\n",
    "tuner_CNN.search(X_train, [y_train_valence, y_train_energy, y_train_danceability], \n",
    "             epochs=20, \n",
    "             validation_data=(X_val, [y_val_valence, y_val_energy, y_val_danceability]), \n",
    "             callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model_CNN = tuner_CNN.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters_CNN = tuner_CNN.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters_CNN.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - danceability_output_accuracy: 0.4052 - energy_output_accuracy: 0.4340 - loss: 3.6213 - valence_output_accuracy: 0.5440  \n",
      "<module 'sklearn.metrics' from 'c:\\\\Users\\\\Alex\\\\anaconda3\\\\envs\\\\pt\\\\Lib\\\\site-packages\\\\sklearn\\\\metrics\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "metrics_CNN = best_model_CNN.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "#print(f'Test Loss: {loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 评估模型\n",
    "# loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "# print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 3\n",
    "\n",
    "class MultiLabelBERT(nn.Module):\n",
    "    def __init__(self, model_name, num_labels_valence, num_labels_energy, num_labels_danceability, dropout_rate):\n",
    "        super(MultiLabelBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier_valence = nn.Linear(self.bert.config.hidden_size, num_labels_valence)\n",
    "        self.classifier_energy = nn.Linear(self.bert.config.hidden_size, num_labels_energy)\n",
    "        self.classifier_danceability = nn.Linear(self.bert.config.hidden_size, num_labels_danceability)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels_valence=None, labels_energy=None, labels_danceability=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        pooled_output = self.dropout(outputs.pooler_output)\n",
    "        \n",
    "        logits_valence = self.classifier_valence(pooled_output)\n",
    "        logits_energy = self.classifier_energy(pooled_output)\n",
    "        logits_danceability = self.classifier_danceability(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels_valence is not None and labels_energy is not None and labels_danceability is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss_valence = loss_fct(logits_valence, labels_valence)\n",
    "            loss_energy = loss_fct(logits_energy, labels_energy)\n",
    "            loss_danceability = loss_fct(logits_danceability, labels_danceability)\n",
    "            loss = loss_valence + loss_energy + loss_danceability\n",
    "        \n",
    "        return (loss, logits_valence, logits_energy, logits_danceability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelRoBERTa(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels_valence, num_labels_energy, num_labels_danceability, dropout_rate):\n",
    "        super(MultiLabelRoBERTa, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.classifier_valence = torch.nn.Linear(self.roberta.config.hidden_size, num_labels_valence)\n",
    "        self.classifier_energy = torch.nn.Linear(self.roberta.config.hidden_size, num_labels_energy)\n",
    "        self.classifier_danceability = torch.nn.Linear(self.roberta.config.hidden_size, num_labels_danceability)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels_valence=None, labels_energy=None, labels_danceability=None):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token = outputs[0][:, 0, :]\n",
    "        cls_token = self.dropout(cls_token)\n",
    "        \n",
    "        logits_valence = self.classifier_valence(cls_token)\n",
    "        logits_energy = self.classifier_energy(cls_token)\n",
    "        logits_danceability = self.classifier_danceability(cls_token)\n",
    "        \n",
    "        loss = 0\n",
    "        if labels_valence is not None and labels_energy is not None and labels_danceability is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss_valence = loss_fct(logits_valence, labels_valence)\n",
    "            loss_energy = loss_fct(logits_energy, labels_energy)\n",
    "            loss_danceability = loss_fct(logits_danceability, labels_danceability)\n",
    "            loss = (loss_valence + loss_energy + loss_danceability) / 3\n",
    "        \n",
    "        return loss, logits_valence, logits_energy, logits_danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRoberta(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels_valence, num_labels_energy, num_labels_danceability, dropout_rate):\n",
    "        super(XLMRoberta, self).__init__()\n",
    "        self.xlm_roberta = XLMRobertaModel.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.classifier_valence = torch.nn.Linear(self.xlm_roberta.config.hidden_size, num_labels_valence)\n",
    "        self.classifier_energy = torch.nn.Linear(self.xlm_roberta.config.hidden_size, num_labels_energy)\n",
    "        self.classifier_danceability = torch.nn.Linear(self.xlm_roberta.config.hidden_size, num_labels_danceability)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels_valence=None, labels_energy=None, labels_danceability=None):\n",
    "        outputs = self.xlm_roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token = outputs[0][:, 0, :]\n",
    "        cls_token = self.dropout(cls_token)\n",
    "        \n",
    "        logits_valence = self.classifier_valence(cls_token)\n",
    "        logits_energy = self.classifier_energy(cls_token)\n",
    "        logits_danceability = self.classifier_danceability(cls_token)\n",
    "        \n",
    "        loss = 0\n",
    "        if labels_valence is not None and labels_energy is not None and labels_danceability is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss_valence = loss_fct(logits_valence, labels_valence)\n",
    "            loss_energy = loss_fct(logits_energy, labels_energy)\n",
    "            loss_danceability = loss_fct(logits_danceability, labels_danceability)\n",
    "            loss = (loss_valence + loss_energy + loss_danceability) / 3\n",
    "        \n",
    "        return loss, logits_valence, logits_energy, logits_danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_class(model_name, num_labels_valence, num_labels_energy, num_labels_danceability, dropout_rate):\n",
    "    model = None\n",
    "    if model_name == 'roberta-base':\n",
    "        model = MultiLabelRoBERTa(model_name, num_labels_valence, num_labels_energy, num_labels_danceability, dropout_rate)\n",
    "    elif model_name == 'bert-base-uncased':\n",
    "        model = MultiLabelBERT(model_name, num_labels_valence, num_labels_energy, num_labels_danceability, dropout_rate)\n",
    "    elif model_name == 'xlm-roberta-base':\n",
    "        model = XLMRoberta(model_name, num_labels_valence, num_labels_energy, num_labels_danceability, dropout_rate)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels_valence, labels_energy, labels_danceability):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels_valence = np.argmax(labels_valence, axis=1)\n",
    "        self.labels_energy = np.argmax(labels_energy, axis=1)\n",
    "        self.labels_danceability = np.argmax(labels_danceability, axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.long),\n",
    "            'labels_valence': torch.tensor(self.labels_valence[idx], dtype=torch.long),\n",
    "            'labels_energy': torch.tensor(self.labels_energy[idx], dtype=torch.long),\n",
    "            'labels_danceability': torch.tensor(self.labels_danceability[idx], dtype=torch.long)\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分数据集\n",
    "max_len = 128\n",
    "X_train_val, X_test, y_train_val_valence, y_test_valence, y_train_val_energy, y_test_energy, y_train_val_danceability, y_test_danceability = train_test_split(\n",
    "    data['lyrics'], y_valence, y_energy, y_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train_valence, y_val_valence, y_train_energy, y_val_energy, y_train_danceability, y_val_danceability = train_test_split(\n",
    "    X_train_val, y_train_val_valence, y_train_val_energy, y_train_val_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "def tokenize(sentences, tokenizer, max_len=128):\n",
    "    input_ids, attention_masks = [], []\n",
    "    for sent in sentences:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text=sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids), np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(params):\n",
    "    lr = params['lr']\n",
    "    num_epochs = int(params['num_epochs'])\n",
    "    batch_size = int(params['batch_size'])\n",
    "    weight_decay = params['weight_decay']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    model_name = params['model_name']\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model_class(model_name, num_labels_valence=3, num_labels_energy=3, num_labels_danceability=3, dropout_rate=dropout_rate).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_dataset = MultiLabelDataset(X_train_input_ids, X_train_attention_masks, y_train_valence, y_train_energy, y_train_danceability)\n",
    "    val_dataset = MultiLabelDataset(X_val_input_ids, X_val_attention_masks, y_val_valence, y_val_energy, y_val_danceability)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    num_training_steps = len(train_dataloader) * num_epochs\n",
    "    warmup_steps = int(0.1 * num_training_steps)\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=num_training_steps)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_accuracy = float(0)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_predictions_valence = []\n",
    "        train_predictions_energy = []\n",
    "        train_predictions_danceability = []\n",
    "        train_labels_valence = []\n",
    "        train_labels_energy = []\n",
    "        train_labels_danceability = []\n",
    "        progress_bar = tqdm(train_dataloader, desc='Training', leave=False)\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels_valence = batch['labels_valence'].to(device)\n",
    "            labels_energy = batch['labels_energy'].to(device)\n",
    "            labels_danceability = batch['labels_danceability'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels_valence=labels_valence, labels_energy=labels_energy, labels_danceability=labels_danceability)\n",
    "            loss, logits_valence, logits_energy, logits_danceability = outputs\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_predictions_valence.extend(logits_valence.argmax(dim=-1).cpu().numpy())\n",
    "            train_predictions_energy.extend(logits_energy.argmax(dim=-1).cpu().numpy())\n",
    "            train_predictions_danceability.extend(logits_danceability.argmax(dim=-1).cpu().numpy())\n",
    "            train_labels_valence.extend(labels_valence.cpu().numpy())\n",
    "            train_labels_energy.extend(labels_energy.cpu().numpy())\n",
    "            train_labels_danceability.extend(labels_danceability.cpu().numpy())\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        train_accuracy_valence = metrics.accuracy_score(train_labels_valence, train_predictions_valence)\n",
    "        train_accuracy_energy = metrics.accuracy_score(train_labels_energy, train_predictions_energy)\n",
    "        train_accuracy_danceability = metrics.accuracy_score(train_labels_danceability, train_predictions_danceability)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_predictions_valence = []\n",
    "        val_predictions_energy = []\n",
    "        val_predictions_danceability = []\n",
    "        val_labels_valence = []\n",
    "        val_labels_energy = []\n",
    "        val_labels_danceability = []\n",
    "        progress_bar = tqdm(val_dataloader, desc='Validation', leave=False)\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels_valence = batch['labels_valence'].to(device)\n",
    "            labels_energy = batch['labels_energy'].to(device)\n",
    "            labels_danceability = batch['labels_danceability'].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels_valence=labels_valence, labels_energy=labels_energy, labels_danceability=labels_danceability)\n",
    "                loss, logits_valence, logits_energy, logits_danceability = outputs\n",
    "                val_loss += loss.item()\n",
    "                val_predictions_valence.extend(logits_valence.argmax(dim=-1).cpu().numpy())\n",
    "                val_predictions_energy.extend(logits_energy.argmax(dim=-1).cpu().numpy())\n",
    "                val_predictions_danceability.extend(logits_danceability.argmax(dim=-1).cpu().numpy())\n",
    "                val_labels_valence.extend(labels_valence.cpu().numpy())\n",
    "                val_labels_energy.extend(labels_energy.cpu().numpy())\n",
    "                val_labels_danceability.extend(labels_danceability.cpu().numpy())\n",
    "                progress_bar.set_postfix({'val_loss': loss.item()})\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        val_accuracy_valence = metrics.accuracy_score(val_labels_valence, val_predictions_valence)\n",
    "        val_accuracy_energy = metrics.accuracy_score(val_labels_energy, val_predictions_energy)\n",
    "        val_accuracy_danceability = metrics.accuracy_score(val_labels_danceability, val_predictions_danceability)\n",
    "\n",
    "        val_accuracy = (val_accuracy_valence + val_accuracy_energy + val_accuracy_danceability) / 3\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), f'best_model{model_name}.pt')\n",
    "            \n",
    "    model.load_state_dict(torch.load(f'best_model{model_name}.pt'))\n",
    "    print(f'No. of Epoch: {epoch}; Validation accuracy: {val_accuracy * 100:.2f}%; train accuracies: valence {train_accuracy_valence * 100:.2f}%, energy {train_accuracy_energy * 100:.2f}%, danceability {train_accuracy_danceability * 100:.2f}%')\n",
    "    return val_accuracy, avg_val_loss, train_accuracy_valence, train_accuracy_energy, train_accuracy_danceability, train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 使用 BertTokenizer 和 TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "X_train_input_ids, X_train_attention_masks = tokenize(X_train, tokenizer, max_len)\n",
    "X_val_input_ids, X_val_attention_masks = tokenize(X_val, tokenizer, max_len)\n",
    "X_test_input_ids, X_test_attention_masks = tokenize(X_test, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_bert(trial):\n",
    "    params = {\n",
    "        'lr': trial.suggest_float('lr', 2e-5, 5e-5, log=True),\n",
    "        'num_epochs': trial.suggest_int('num_epochs', 4, 10),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 0.01, 0.3),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.05, 0.3),\n",
    "        'model_name': 'bert-base-uncased'\n",
    "    }\n",
    "    val_accuracy, avg_val_loss, train_accuracy_valence, train_accuracy_energy, train_accuracy_danceability, train_loss = train_and_evaluate(params)\n",
    "    trial.set_user_attr(\"val_accuracy\", val_accuracy)\n",
    "    trial.set_user_attr(\"avg_val_loss\", avg_val_loss)\n",
    "    trial.set_user_attr(\"train_accuracy_valence\", train_accuracy_valence)\n",
    "    trial.set_user_attr(\"train_accuracy_energy\", train_accuracy_energy)\n",
    "    trial.set_user_attr(\"train_accuracy_danceability\", train_accuracy_danceability)\n",
    "    trial.set_user_attr(\"train_loss\", train_loss)\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:31:25,077] A new study created in memory with name: no-name-3959ab83-99a1-4555-86e7-d8b011e601aa\n",
      "Training:   0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "[I 2024-05-21 17:32:06,253] Trial 0 finished with value: 3.2556811571121216 and parameters: {'lr': 3.881238115889723e-05, 'num_epochs': 8, 'batch_size': 64, 'weight_decay': 0.26322440438232725, 'dropout_rate': 0.2715328059343429}. Best is trial 0 with value: 3.2556811571121216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 7; Validation accuracy: 41.32%; train accuracies: valence 46.88%, energy 46.09%, danceability 61.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:33:06,725] Trial 1 finished with value: 3.0864136616388955 and parameters: {'lr': 2.4928069352434043e-05, 'num_epochs': 10, 'batch_size': 16, 'weight_decay': 0.08007780288730042, 'dropout_rate': 0.19357245340483503}. Best is trial 1 with value: 3.0864136616388955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 9; Validation accuracy: 49.65%; train accuracies: valence 77.60%, energy 73.96%, danceability 81.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:33:35,047] Trial 2 finished with value: 3.191865086555481 and parameters: {'lr': 2.870240237409906e-05, 'num_epochs': 5, 'batch_size': 64, 'weight_decay': 0.19239259526771582, 'dropout_rate': 0.05029337097032434}. Best is trial 1 with value: 3.0864136616388955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 4; Validation accuracy: 42.36%; train accuracies: valence 45.57%, energy 52.08%, danceability 64.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:34:04,964] Trial 3 finished with value: 3.112999598185221 and parameters: {'lr': 3.918162545879459e-05, 'num_epochs': 5, 'batch_size': 16, 'weight_decay': 0.2867286053768651, 'dropout_rate': 0.2880915278877951}. Best is trial 1 with value: 3.0864136616388955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 4; Validation accuracy: 44.10%; train accuracies: valence 60.68%, energy 52.60%, danceability 59.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:34:58,451] Trial 4 finished with value: 3.108652035395304 and parameters: {'lr': 2.2512227644146603e-05, 'num_epochs': 9, 'batch_size': 16, 'weight_decay': 0.028614203665095664, 'dropout_rate': 0.09050785353432421}. Best is trial 1 with value: 3.0864136616388955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 8; Validation accuracy: 50.69%; train accuracies: valence 69.01%, energy 72.92%, danceability 76.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:35:54,080] Trial 5 finished with value: 3.0938605467478433 and parameters: {'lr': 3.847523007788696e-05, 'num_epochs': 10, 'batch_size': 32, 'weight_decay': 0.0640133110121321, 'dropout_rate': 0.0939758181442993}. Best is trial 1 with value: 3.0864136616388955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 9; Validation accuracy: 50.35%; train accuracies: valence 83.07%, energy 85.42%, danceability 84.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:36:22,709] Trial 6 finished with value: 3.1062621672948203 and parameters: {'lr': 2.837596102006958e-05, 'num_epochs': 5, 'batch_size': 16, 'weight_decay': 0.045331038799320454, 'dropout_rate': 0.07726064118970859}. Best is trial 1 with value: 3.0864136616388955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 4; Validation accuracy: 46.53%; train accuracies: valence 69.53%, energy 60.94%, danceability 67.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:37:09,251] Trial 7 finished with value: 3.0847971439361572 and parameters: {'lr': 3.8290506222532054e-05, 'num_epochs': 10, 'batch_size': 64, 'weight_decay': 0.22409560346314, 'dropout_rate': 0.1154595228131677}. Best is trial 7 with value: 3.0847971439361572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 9; Validation accuracy: 47.57%; train accuracies: valence 77.60%, energy 66.15%, danceability 63.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:37:55,270] Trial 8 finished with value: 2.9503024419148765 and parameters: {'lr': 2.1958855848517977e-05, 'num_epochs': 9, 'batch_size': 32, 'weight_decay': 0.1539785454806838, 'dropout_rate': 0.057008010800600126}. Best is trial 8 with value: 2.9503024419148765.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 8; Validation accuracy: 51.74%; train accuracies: valence 64.32%, energy 73.18%, danceability 83.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:38:17,652] Trial 9 finished with value: 3.2274989684422812 and parameters: {'lr': 4.1805430970610263e-05, 'num_epochs': 4, 'batch_size': 16, 'weight_decay': 0.040642854638596584, 'dropout_rate': 0.2935984349410949}. Best is trial 8 with value: 2.9503024419148765.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 3; Validation accuracy: 43.06%; train accuracies: valence 40.62%, energy 45.31%, danceability 47.14%\n",
      "Best hyperparameters:  {'lr': 2.1958855848517977e-05, 'num_epochs': 9, 'batch_size': 32, 'weight_decay': 0.1539785454806838, 'dropout_rate': 0.057008010800600126}\n",
      "Best value (negative validation loss):  2.9503024419148765\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity_error()\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_bert, n_trials=10)\n",
    "\n",
    "print('Best hyperparameters: ', study.best_params)\n",
    "print('Best value (negative validation loss): ', study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "class BertLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "        self.bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_ids, attention_mask = inputs\n",
    "        bert_output = self.bert_model([input_ids, attention_mask])\n",
    "        cls_token = bert_output.last_hidden_state[:, 0, :]\n",
    "        return cls_token\n",
    "\n",
    "def build_bert_model():\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "    bert_layer = BertLayer()\n",
    "    cls_token = bert_layer([input_ids, attention_mask])\n",
    "    cls_token = Dropout(0.3)(cls_token)\n",
    "\n",
    "    dense_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[dense_valence, dense_energy, dense_danceability])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_bert_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# 设置学习率调度器\n",
    "num_train_steps = len(X_train_input_ids) // 16 * 5  # 数据量 / batch_size * epochs\n",
    "num_warmup_steps = num_train_steps // 10  # 通常设置为训练步骤的10%\n",
    "\n",
    "optimizer = Adam(learning_rate=tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=2e-5,\n",
    "    decay_steps=num_train_steps,\n",
    "    end_learning_rate=0.0\n",
    "))\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss={'valence_output': 'categorical_crossentropy', \n",
    "                    'energy_output': 'categorical_crossentropy', \n",
    "                    'danceability_output': 'categorical_crossentropy'},\n",
    "              metrics={'valence_output': 'accuracy', \n",
    "                       'energy_output': 'accuracy', \n",
    "                       'danceability_output': 'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_input_ids, X_train_attention_masks],\n",
    "    {'valence_output': y_train_valence, 'energy_output': y_train_energy, 'danceability_output': y_train_danceability},\n",
    "    validation_data=([X_val_input_ids, X_val_attention_masks], {'valence_output': y_val_valence, 'energy_output': y_val_energy, 'danceability_output': y_val_danceability}),\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = model.evaluate(\n",
    "    [X_test_input_ids, X_test_attention_masks], \n",
    "    [y_test_valence, y_test_energy, y_test_danceability]\n",
    ")\n",
    "\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}')\n",
    "print(f'Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have implemented lr and weight decay onto this, therefore it has warm up and decay now with l2 reg, and i only ran 5 epochs because its quite slow on my mac, I noticed the loss is still decreasing drastically, therefore i believe runing more epochs will eventually boost the acc by a lot, can you guys make it 10-15 epochs and test out whats going on at that. Thx, ill now push this version onto github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "max_len = 128\n",
    "\n",
    "X_train_input_ids, X_train_attention_masks = tokenize(X_train, tokenizer, max_len)\n",
    "X_val_input_ids, X_val_attention_masks = tokenize(X_val, tokenizer, max_len)\n",
    "X_test_input_ids, X_test_attention_masks = tokenize(X_test, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoBERTaLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoBERTaLayer, self).__init__(**kwargs)\n",
    "        self.roberta_model = TFRobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_ids, attention_mask = inputs\n",
    "        roberta_output = self.roberta_model([input_ids, attention_mask])\n",
    "        cls_token = roberta_output.last_hidden_state[:, 0, :]\n",
    "        return cls_token\n",
    "\n",
    "def build_bert_model():\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "    bert_layer = BertLayer()\n",
    "    cls_token = bert_layer([input_ids, attention_mask])\n",
    "    cls_token = Dropout(0.3)(cls_token)\n",
    "\n",
    "    dense_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[dense_valence, dense_energy, dense_danceability])\n",
    "    return model\n",
    "\n",
    "def build_roberta_model():\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    roberta_layer = RoBERTaLayer()\n",
    "    cls_token = roberta_layer([input_ids, attention_mask])\n",
    "    cls_token = Dropout(0.3)(cls_token)\n",
    "\n",
    "    dense_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[dense_valence, dense_energy, dense_danceability])\n",
    "    return model\n",
    "\n",
    "def get_optimizer_and_scheduler(num_train_steps, num_warmup_steps):\n",
    "    optimizer = Adam(learning_rate=2e-5, weight_decay=0.01)\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "    return optimizer, lr_scheduler\n",
    "\n",
    "num_train_steps = len(X_train_input_ids) // 16 * 5\n",
    "num_warmup_steps = num_train_steps // 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_roberta_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# 设置学习率调度器\n",
    "num_train_steps = len(X_train_input_ids) // 16 * 5\n",
    "num_warmup_steps = num_train_steps // 10 \n",
    "\n",
    "optimizer = Adam(learning_rate=tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=2e-5,\n",
    "    decay_steps=num_train_steps,\n",
    "    end_learning_rate=0.0\n",
    "))\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss={'valence_output': 'categorical_crossentropy', \n",
    "                    'energy_output': 'categorical_crossentropy', \n",
    "                    'danceability_output': 'categorical_crossentropy'},\n",
    "              metrics={'valence_output': 'accuracy', \n",
    "                       'energy_output': 'accuracy', \n",
    "                       'danceability_output': 'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_input_ids, X_train_attention_masks],\n",
    "    {'valence_output': y_train_valence, 'energy_output': y_train_energy, 'danceability_output': y_train_danceability},\n",
    "    validation_data=([X_val_input_ids, X_val_attention_masks], {'valence_output': y_val_valence, 'energy_output': y_val_energy, 'danceability_output': y_val_danceability}),\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_loss, roberta_valence_output_loss, roberta_energy_output_loss, roberta_danceability_output_loss, roberta_accuracy_valence, roberta_accuracy_energy, roberta_accuracy_danceability = model.evaluate(\n",
    "    [X_test_input_ids, X_test_attention_masks], \n",
    "    [y_test_valence, y_test_energy, y_test_danceability]\n",
    ")\n",
    "\n",
    "\n",
    "print(f'Test Loss: {roberta_loss}, valence_output_loss: {roberta_valence_output_loss}, energy_output_loss: {roberta_energy_output_loss}, danceability_output_loss: {roberta_accuracy_valence}')\n",
    "print(f'Test Accuracy Valence: {roberta_accuracy_valence}, Test Accuracy Energy: {roberta_accuracy_energy}, Test Accuracy Danceability: {roberta_accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_roberta(trial):\n",
    "    params = {\n",
    "        'lr': trial.suggest_float('lr', 2e-5, 5e-5, log=True),\n",
    "        'num_epochs': trial.suggest_int('num_epochs', 4, 10),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 0.01, 0.3),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.05, 0.3),\n",
    "        'model_name' : 'roberta-base',\n",
    "    }\n",
    "    val_accuracy, avg_val_loss, train_accuracy_valence, train_accuracy_energy, train_accuracy_danceability, train_loss = train_and_evaluate(params)\n",
    "    trial.set_user_attr(\"val_accuracy\", val_accuracy)\n",
    "    trial.set_user_attr(\"avg_val_loss\", avg_val_loss)\n",
    "    trial.set_user_attr(\"train_accuracy_valence\", train_accuracy_valence)\n",
    "    trial.set_user_attr(\"train_accuracy_energy\", train_accuracy_energy)\n",
    "    trial.set_user_attr(\"train_accuracy_danceability\", train_accuracy_danceability)\n",
    "    trial.set_user_attr(\"train_loss\", train_loss)\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:39:22,257] A new study created in memory with name: no-name-1269b4b6-3c6f-44fb-bbb0-e54d784c5381\n",
      "[I 2024-05-21 17:40:49,709] Trial 0 finished with value: 1.1033253073692322 and parameters: {'lr': 2.0329938663928718e-05, 'num_epochs': 5, 'batch_size': 64, 'weight_decay': 0.13128676609527015, 'dropout_rate': 0.2125115273215718}. Best is trial 0 with value: 1.1033253073692322.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 4; Validation accuracy: 36.11%; train accuracies: valence 37.76%, energy 44.53%, danceability 47.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:42:35,341] Trial 1 finished with value: 1.1011657118797302 and parameters: {'lr': 2.1498706325667825e-05, 'num_epochs': 5, 'batch_size': 64, 'weight_decay': 0.17309629156005488, 'dropout_rate': 0.19528781006618745}. Best is trial 1 with value: 1.1011657118797302.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 4; Validation accuracy: 39.24%; train accuracies: valence 38.28%, energy 40.62%, danceability 42.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:43:01,340] Trial 2 finished with value: 1.1023189822832744 and parameters: {'lr': 3.685182279362353e-05, 'num_epochs': 4, 'batch_size': 16, 'weight_decay': 0.025766292975500024, 'dropout_rate': 0.14525775119411688}. Best is trial 1 with value: 1.1011657118797302.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 3; Validation accuracy: 37.15%; train accuracies: valence 36.46%, energy 44.27%, danceability 44.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:43:25,523] Trial 3 finished with value: 1.0924159089724224 and parameters: {'lr': 2.8818798332946995e-05, 'num_epochs': 4, 'batch_size': 16, 'weight_decay': 0.19742560417808025, 'dropout_rate': 0.2274185815203844}. Best is trial 3 with value: 1.0924159089724224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 3; Validation accuracy: 38.89%; train accuracies: valence 36.72%, energy 40.62%, danceability 42.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:44:18,021] Trial 4 finished with value: 1.0849867661794026 and parameters: {'lr': 3.4727942858464604e-05, 'num_epochs': 9, 'batch_size': 16, 'weight_decay': 0.10098697563054883, 'dropout_rate': 0.10149242456202064}. Best is trial 4 with value: 1.0849867661794026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 8; Validation accuracy: 42.01%; train accuracies: valence 58.85%, energy 64.06%, danceability 63.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:45:21,531] Trial 5 finished with value: 1.0950578451156616 and parameters: {'lr': 4.1900851479988604e-05, 'num_epochs': 7, 'batch_size': 64, 'weight_decay': 0.17836355031387507, 'dropout_rate': 0.08582905507578333}. Best is trial 4 with value: 1.0849867661794026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 6; Validation accuracy: 44.79%; train accuracies: valence 50.26%, energy 51.56%, danceability 53.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:46:19,066] Trial 6 finished with value: 1.1655245820681255 and parameters: {'lr': 3.208465225206525e-05, 'num_epochs': 10, 'batch_size': 16, 'weight_decay': 0.19619049875417097, 'dropout_rate': 0.2717387386491114}. Best is trial 4 with value: 1.0849867661794026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 9; Validation accuracy: 51.04%; train accuracies: valence 86.46%, energy 86.72%, danceability 82.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:48:00,125] Trial 7 finished with value: 1.100628137588501 and parameters: {'lr': 2.522423456386463e-05, 'num_epochs': 8, 'batch_size': 64, 'weight_decay': 0.18972938932495473, 'dropout_rate': 0.17970741576577443}. Best is trial 4 with value: 1.0849867661794026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 7; Validation accuracy: 42.01%; train accuracies: valence 44.79%, energy 47.66%, danceability 55.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:48:31,219] Trial 8 finished with value: 1.0942775408426921 and parameters: {'lr': 3.4441202059740275e-05, 'num_epochs': 5, 'batch_size': 32, 'weight_decay': 0.047273561082108236, 'dropout_rate': 0.11300513613666673}. Best is trial 4 with value: 1.0849867661794026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 4; Validation accuracy: 40.62%; train accuracies: valence 36.98%, energy 44.53%, danceability 45.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:49:18,843] Trial 9 finished with value: 1.135833462079366 and parameters: {'lr': 2.412610360582795e-05, 'num_epochs': 8, 'batch_size': 16, 'weight_decay': 0.2888010093362711, 'dropout_rate': 0.10280913018791517}. Best is trial 4 with value: 1.0849867661794026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 7; Validation accuracy: 42.36%; train accuracies: valence 76.56%, energy 65.89%, danceability 69.01%\n",
      "Best hyperparameters:  {'lr': 3.4727942858464604e-05, 'num_epochs': 9, 'batch_size': 16, 'weight_decay': 0.10098697563054883, 'dropout_rate': 0.10149242456202064}\n",
      "Best value (negative validation loss):  1.0849867661794026\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity_error()\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_roberta, n_trials=10)\n",
    "\n",
    "print('Best hyperparameters: ', study.best_params)\n",
    "print('Best value (negative validation loss): ', study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLM Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "max_len = 128\n",
    "\n",
    "X_train_input_ids, X_train_attention_masks = tokenize(X_train, tokenizer, max_len)\n",
    "X_val_input_ids, X_val_attention_masks = tokenize(X_val, tokenizer, max_len)\n",
    "X_test_input_ids, X_test_attention_masks = tokenize(X_test, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xlm_roberta(trial):\n",
    "    params = {\n",
    "        'lr': trial.suggest_float('lr', 2e-5, 5e-5, log=True),\n",
    "        'num_epochs': trial.suggest_int('num_epochs', 4, 10),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 0.01, 0.3),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.05, 0.3),\n",
    "        'model_name' : 'xlm-roberta-base',\n",
    "    }\n",
    "    val_accuracy, avg_val_loss, train_accuracy_valence, train_accuracy_energy, train_accuracy_danceability, train_loss = train_and_evaluate(params)\n",
    "    trial.set_user_attr(\"val_accuracy\", val_accuracy)\n",
    "    trial.set_user_attr(\"avg_val_loss\", avg_val_loss)\n",
    "    trial.set_user_attr(\"train_accuracy_valence\", train_accuracy_valence)\n",
    "    trial.set_user_attr(\"train_accuracy_energy\", train_accuracy_energy)\n",
    "    trial.set_user_attr(\"train_accuracy_danceability\", train_accuracy_danceability)\n",
    "    trial.set_user_attr(\"train_loss\", train_loss)\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-21 17:51:00,497] A new study created in memory with name: no-name-2bbb5723-6a34-4475-9b80-3cc917c95bd5\n",
      "[I 2024-05-21 17:52:02,298] Trial 0 finished with value: 1.093851923942566 and parameters: {'lr': 4.5262511107956246e-05, 'num_epochs': 7, 'batch_size': 16, 'weight_decay': 0.21902998437637922, 'dropout_rate': 0.0712138360909524}. Best is trial 0 with value: 1.093851923942566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Epoch: 6; Validation accuracy: 34.38%; train accuracies: valence 37.50%, energy 36.46%, danceability 41.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-05-21 18:03:06,348] Trial 1 failed with parameters: {'lr': 2.4679163498068568e-05, 'num_epochs': 7, 'batch_size': 64, 'weight_decay': 0.22847151379840608, 'dropout_rate': 0.13112821185437346} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_7700\\646330640.py\", line 10, in objective_xlm_roberta\n",
      "    val_accuracy, avg_val_loss, train_accuracy_valence, train_accuracy_energy, train_accuracy_danceability, train_loss = train_and_evaluate(params)\n",
      "                                                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_7700\\404054282.py\", line 53, in train_and_evaluate\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\torch\\_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\torch\\autograd\\graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-05-21 18:03:06,351] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m logging\u001b[38;5;241m.\u001b[39mset_verbosity_error()\n\u001b[0;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_xlm_roberta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest value (negative validation loss): \u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_value)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[30], line 10\u001b[0m, in \u001b[0;36mobjective_xlm_roberta\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective_xlm_roberta\u001b[39m(trial):\n\u001b[0;32m      2\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2e-5\u001b[39m, \u001b[38;5;241m5e-5\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlm-roberta-base\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     }\n\u001b[1;32m---> 10\u001b[0m     val_accuracy, avg_val_loss, train_accuracy_valence, train_accuracy_energy, train_accuracy_danceability, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     trial\u001b[38;5;241m.\u001b[39mset_user_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_accuracy)\n\u001b[0;32m     12\u001b[0m     trial\u001b[38;5;241m.\u001b[39mset_user_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_val_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, avg_val_loss)\n",
      "Cell \u001b[1;32mIn[23], line 53\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     51\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, labels_valence\u001b[38;5;241m=\u001b[39mlabels_valence, labels_energy\u001b[38;5;241m=\u001b[39mlabels_energy, labels_danceability\u001b[38;5;241m=\u001b[39mlabels_danceability)\n\u001b[0;32m     52\u001b[0m loss, logits_valence, logits_energy, logits_danceability \u001b[38;5;241m=\u001b[39m outputs\n\u001b[1;32m---> 53\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     55\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logging.set_verbosity_error()\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_xlm_roberta, n_trials=3)\n",
    "\n",
    "print('Best hyperparameters: ', study.best_params)\n",
    "print('Best value (negative validation loss): ', study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time_DNN = 22.3 / 20\n",
    "time_bi_LSTM = (39.9 + (6 * 60))/20\n",
    "time_CNN = 28.3 / 20\n",
    "time_BERT = (52.5 + (6 * 60))/10\n",
    "time_RoBERTa = (56.5 + (9 * 60))/10\n",
    "time_XMLRoBERTa = (54 + (24 * 60))/2\n",
    "\n",
    "times = [time_DNN, time_bi_LSTM, time_CNN, time_BERT, time_RoBERTa]\n",
    "names = ['DNN', 'bi-LSTM', 'CNN', 'BERT', 'RoBERTa']\n",
    "\n",
    "sorted_data = sorted(zip(names, times), key=lambda x: x[1])\n",
    "sorted_names, sorted_times = zip(*sorted_data)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(sorted_names, sorted_times, color='skyblue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.title('Execution Time for Different Models per Each Trial')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add time values at the top of each bar\n",
    "for bar, time in zip(bars, sorted_times):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{time:.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 12288, but received input with shape (32, 96)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(32, 1), dtype=string)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m best_model_DNN \u001b[38;5;241m=\u001b[39m dnn_tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mbest_model_DNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train_val_valence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_val_energy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_val_danceability\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\pt\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 12288, but received input with shape (32, 96)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(32, 1), dtype=string)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "best_model_DNN = dnn_tuner.get_best_models(num_models=1)[0]\n",
    "best_model_DNN.fit(X_train_val, [y_train_val_valence, y_train_val_energy, y_train_val_danceability], epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_output_dim': 96, 'filters': 96, 'kernel_size': 7, 'pool_size': 5, 'num_layers': 3, 'dense_units_1': 288, 'dropout_1': 0.0, 'optimizer': 'rmsprop', 'learning_rate': 0.001, 'dense_units_2': 224, 'dropout_2': 0.30000000000000004, 'dense_units_3': 32, 'dropout_3': 0.0}\n"
     ]
    }
   ],
   "source": [
    "best_model_CNN = tuner_CNN.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters_CNN = tuner_CNN.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters_CNN.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model bi_lstm_mood_detection:\n",
      "  val_danceability_acc: [0.4479166567325592, 0.40625, 0.3645833432674408, 0.4166666567325592, 0.4791666567325592, 0.2708333432674408, 0.5104166865348816, 0.4375, 0.3020833432674408, 0.4583333432674408]\n",
      "  val_energy_acc: [0.2916666567325592, 0.34375, 0.3229166567325592, 0.3541666567325592, 0.40625, 0.2916666567325592, 0.3541666567325592, 0.46875, 0.2708333432674408, 0.3854166567325592]\n",
      "  val_valence_acc: [0.5, 0.4791666567325592, 0.46875, 0.4375, 0.4270833432674408, 0.34375, 0.4583333432674408, 0.4479166567325592, 0.3645833432674408, 0.4479166567325592]\n",
      "  val_loss: [3.2785587310791016, 3.1993112564086914, 3.294572591781616, 3.293623924255371, 3.1806838512420654, 3.290111541748047, 3.1452789306640625, 3.490560531616211, 3.2970426082611084, 3.189159393310547]\n",
      "  danceability_acc: [0.5677083134651184, 0.4661458432674408, 0.2760416567325592, 0.3880208432674408, 0.5182291865348816, 0.3880208432674408, 0.4895833432674408, 0.5859375, 0.3515625, 0.4739583432674408]\n",
      "  energy_acc: [0.5572916865348816, 0.4140625, 0.3541666567325592, 0.3046875, 0.4635416567325592, 0.4244791567325592, 0.46875, 0.7942708134651184, 0.3151041567325592, 0.4296875]\n",
      "  valence_acc: [0.5182291865348816, 0.4010416567325592, 0.3619791567325592, 0.3802083432674408, 0.4166666567325592, 0.3619791567325592, 0.4140625, 0.5755208134651184, 0.3046875, 0.4192708432674408]\n",
      "  loss: [2.767350435256958, 3.159025192260742, 3.2954890727996826, 3.294626235961914, 3.133417844772339, 3.2843973636627197, 3.0618019104003906, 2.1977479457855225, 3.2958500385284424, 3.151273488998413]\n",
      "----------------------------------------\n",
      "Metrics for model cnn_mood_detection_600:\n",
      "  val_danceability_acc: [0.4270833432674408, 0.4791666567325592, 0.25, 0.2708333432674408, 0.3854166567325592, 0.46875, 0.4166666567325592, 0.2708333432674408, 0.3125, 0.2916666567325592]\n",
      "  val_energy_acc: [0.3645833432674408, 0.4270833432674408, 0.3333333432674408, 0.3958333432674408, 0.3125, 0.3854166567325592, 0.4375, 0.375, 0.3541666567325592, 0.34375]\n",
      "  val_valence_acc: [0.4166666567325592, 0.5625, 0.34375, 0.40625, 0.4166666567325592, 0.46875, 0.5, 0.3854166567325592, 0.3541666567325592, 0.3645833432674408]\n",
      "  val_loss: [3.2701971530914307, 3.592888593673706, 3.295300245285034, 3.2956674098968506, 3.2972793579101562, 3.5491132736206055, 3.172837495803833, 3.2957687377929688, 3.2970199584960938, 3.295557975769043]\n",
      "  danceability_acc: [0.5208333134651184, 0.7421875, 0.3697916567325592, 0.2135416716337204, 0.3098958432674408, 0.7421875, 0.5520833134651184, 0.25, 0.2708333432674408, 0.3359375]\n",
      "  energy_acc: [0.3854166567325592, 0.6796875, 0.4453125, 0.359375, 0.2630208432674408, 0.6979166865348816, 0.5598958134651184, 0.3463541567325592, 0.3489583432674408, 0.4088541567325592]\n",
      "  valence_acc: [0.4791666567325592, 0.7421875, 0.3619791567325592, 0.3671875, 0.3020833432674408, 0.7864583134651184, 0.4973958432674408, 0.3645833432674408, 0.3385416567325592, 0.3255208432674408]\n",
      "  loss: [3.2288990020751953, 1.814821720123291, 3.286893844604492, 3.296921730041504, 3.3026647567749023, 1.959710717201233, 2.887617349624634, 3.2982375621795654, 3.2976701259613037, 3.2939612865448]\n",
      "----------------------------------------\n",
      "Metrics for model dnn_mood_detection_600:\n",
      "  val_danceability_acc: [0.4375, 0.375, 0.5, 0.40625, 0.3125, 0.3020833432674408, 0.21875, 0.4166666567325592]\n",
      "  val_energy_acc: [0.375, 0.3333333432674408, 0.3645833432674408, 0.4583333432674408, 0.3333333432674408, 0.34375, 0.2291666716337204, 0.34375]\n",
      "  val_valence_acc: [0.5520833134651184, 0.28125, 0.5520833134651184, 0.5520833134651184, 0.4166666567325592, 0.5, 0.4479166567325592, 0.40625]\n",
      "  val_loss: [3.300745725631714, 3.6151363849639893, 4.224305629730225, 3.3170974254608154, 3.3311612606048584, 3.3202903270721436, 3.4274394512176514, 3.2931454181671143]\n",
      "  danceability_acc: [0.71875, 0.40625, 0.890625, 0.9427083134651184, 0.3854166567325592, 0.4453125, 0.3020833432674408, 0.3802083432674408]\n",
      "  energy_acc: [0.6458333134651184, 0.3932291567325592, 0.8958333134651184, 0.8671875, 0.328125, 0.4270833432674408, 0.2395833283662796, 0.453125]\n",
      "  valence_acc: [0.8463541865348816, 0.3697916567325592, 0.8776041865348816, 0.9401041865348816, 0.3411458432674408, 0.4088541567325592, 0.3645833432674408, 0.4427083432674408]\n",
      "  loss: [1.7935715913772583, 3.6141910552978516, 0.9519992470741272, 1.5498007535934448, 3.330294370651245, 3.160778045654297, 3.4287025928497314, 3.2911646366119385]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_metric_value(metrics, key, default_value=None):\n",
    "    \"\"\"\n",
    "    Helper function to safely extract metric value from the metrics dictionary.\n",
    "    \"\"\"\n",
    "    if key in metrics:\n",
    "        return metrics[key]['observations'][0]['value'][0]\n",
    "    else:\n",
    "        return default_value\n",
    "\n",
    "def read_trial_metrics(trial_dir):\n",
    "    trial_json = os.path.join(trial_dir, 'trial.json')\n",
    "    with open(trial_json, 'r') as f:\n",
    "        trial_data = json.load(f)\n",
    "\n",
    "    metrics = trial_data['metrics']['metrics']\n",
    "\n",
    "    val_danceability_acc = get_metric_value(metrics, 'val_danceability_output_accuracy')\n",
    "    val_energy_acc = get_metric_value(metrics, 'val_energy_output_accuracy')\n",
    "    val_valence_acc = get_metric_value(metrics, 'val_valence_output_accuracy')\n",
    "    val_loss = get_metric_value(metrics, 'val_loss')\n",
    "\n",
    "    danceability_acc = get_metric_value(metrics, 'danceability_output_accuracy')\n",
    "    energy_acc = get_metric_value(metrics, 'energy_output_accuracy')\n",
    "    valence_acc = get_metric_value(metrics, 'valence_output_accuracy')\n",
    "    loss = get_metric_value(metrics, 'loss')\n",
    "\n",
    "    return {\n",
    "        'val_danceability_acc': val_danceability_acc,\n",
    "        'val_energy_acc': val_energy_acc,\n",
    "        'val_valence_acc': val_valence_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'danceability_acc': danceability_acc,\n",
    "        'energy_acc': energy_acc,\n",
    "        'valence_acc': valence_acc,\n",
    "        'loss': loss\n",
    "    }\n",
    "\n",
    "# Specify the parent directory containing the model folders\n",
    "parent_dir = 'tuner_dir'\n",
    "\n",
    "# Dictionary to store metrics for each model\n",
    "all_model_metrics = {}\n",
    "\n",
    "for model_dir in ['bi_lstm_mood_detection', 'cnn_mood_detection_600', 'dnn_mood_detection_600']:\n",
    "    model_path = os.path.join(parent_dir, model_dir)\n",
    "\n",
    "    # Dictionary to store metrics for all trials in this model\n",
    "    model_metrics = {\n",
    "        'val_danceability_acc': [],\n",
    "        'val_energy_acc': [],\n",
    "        'val_valence_acc': [],\n",
    "        'val_loss': [],\n",
    "        'danceability_acc': [],\n",
    "        'energy_acc': [],\n",
    "        'valence_acc': [],\n",
    "        'loss': []\n",
    "    }\n",
    "\n",
    "    for trial_dir in os.listdir(model_path):\n",
    "        if trial_dir.startswith('trial'):\n",
    "            trial_path = os.path.join(model_path, trial_dir)\n",
    "            metrics = read_trial_metrics(trial_path)\n",
    "            # Append metrics to the respective lists in this model's dictionary\n",
    "            model_metrics['val_danceability_acc'].append(metrics['val_danceability_acc'])\n",
    "            model_metrics['val_energy_acc'].append(metrics['val_energy_acc'])\n",
    "            model_metrics['val_valence_acc'].append(metrics['val_valence_acc'])\n",
    "            model_metrics['val_loss'].append(metrics['val_loss'])\n",
    "            model_metrics['danceability_acc'].append(metrics['danceability_acc'])\n",
    "            model_metrics['energy_acc'].append(metrics['energy_acc'])\n",
    "            model_metrics['valence_acc'].append(metrics['valence_acc'])\n",
    "            model_metrics['loss'].append(metrics['loss'])\n",
    "    \n",
    "    valid_indices = [i for i, _ in enumerate(model_metrics['val_danceability_acc']) \n",
    "                     if None not in [model_metrics['val_danceability_acc'][i], \n",
    "                                     model_metrics['val_energy_acc'][i], \n",
    "                                     model_metrics['val_valence_acc'][i], \n",
    "                                     model_metrics['val_loss'][i], \n",
    "                                     model_metrics['danceability_acc'][i], \n",
    "                                     model_metrics['energy_acc'][i], \n",
    "                                     model_metrics['valence_acc'][i], \n",
    "                                     model_metrics['loss'][i]]]\n",
    "\n",
    "    for key in model_metrics.keys():\n",
    "        model_metrics[key] = [model_metrics[key][i] for i in valid_indices]\n",
    "        \n",
    "    # Store this model's metrics in the all_model_metrics dictionary\n",
    "    all_model_metrics[model_dir] = model_metrics\n",
    "    \n",
    "for model, metrics in all_model_metrics.items():\n",
    "    print(f\"Metrics for model {model}:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[41.31944378217061,\n",
       "  40.97222189108531,\n",
       "  38.54166666666667,\n",
       "  40.27777711550395,\n",
       "  43.75,\n",
       "  30.208333333333332,\n",
       "  44.09722288449605,\n",
       "  45.13888855775197,\n",
       "  31.250000993410747,\n",
       "  43.05555522441864],\n",
       " [40.27777810891469,\n",
       "  48.95833333333333,\n",
       "  30.902778108914692,\n",
       "  35.76388955116272,\n",
       "  37.15277711550395,\n",
       "  44.09722189108531,\n",
       "  45.13888855775197,\n",
       "  34.375,\n",
       "  34.02777711550395,\n",
       "  33.33333333333333],\n",
       " [45.48611044883728,\n",
       "  32.98611144224803,\n",
       "  47.22222189108531,\n",
       "  47.22222189108531,\n",
       "  35.41666666666667,\n",
       "  38.19444477558136,\n",
       "  29.861110945542652,\n",
       "  38.88888855775197]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_list = ['val_danceability_acc', 'val_energy_acc', 'val_valence_acc']\n",
    "acc_list = ['danceability_acc', 'energy_acc', 'valence_acc']\n",
    "\n",
    "def var_sum(dict, selected_list):\n",
    "    val_total = []\n",
    "    for element in dict.values():\n",
    "        val_acc_sum = []\n",
    "        for i in range(len(element['val_danceability_acc'])):\n",
    "            danceability = element['val_danceability_acc'][i]\n",
    "            energy = element['val_energy_acc'][i]\n",
    "            valence = element['val_valence_acc'][i]\n",
    "            val_sum = ((danceability + energy + valence)/ 3) * 100\n",
    "            val_acc_sum.append(val_sum)  \n",
    "        val_total.append(val_acc_sum)\n",
    "\n",
    "    return val_total\n",
    "var_sum(all_model_metrics, val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample data (replace with your own lists)\n",
    "dnn_val_accuracy, lstm_val_accuracy, cnn_val_accuracy = var_sum(all_model_metrics, val_list)\n",
    "bert_tuned_val_accuracy = [41.32, 49.65, 42.36, 44.10, 50.69, 50.35, 46.53, 47.57, 51.74, 43.06]\n",
    "roberta_tuned_val_accuracy = [36.11, 39.24, 37.15, 38.89, 42.01, 44.79, 51.04, 42.01, 40.62, 42.36]\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create the box plot\n",
    "box_plot_accuracy = [dnn_val_accuracy, lstm_val_accuracy, cnn_val_accuracy, bert_tuned_val_accuracy, roberta_tuned_val_accuracy]\n",
    "box = ax.boxplot(box_plot_accuracy, vert=True, patch_artist=True)\n",
    "\n",
    "# Customize the appearance\n",
    "ax.set_title('Average Validation Accuracy of Different Models')\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Percentage Validation Accuracy (%)')\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "ax.set_xticklabels(['DNN', 'Bi-LSTM', 'CNN', 'BERT', 'RoBERTa'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_list_acc = [\n",
    "    \"valence 37.76%, energy 44.53%, danceability 47.92%\",\n",
    "    \"valence 38.28%, energy 40.62%, danceability 42.97%\",\n",
    "    \"valence 36.46%, energy 44.27%, danceability 44.01%\",\n",
    "    \"valence 36.72%, energy 40.62%, danceability 42.71%\",\n",
    "    \"valence 58.85%, energy 64.06%, danceability 63.54%\",\n",
    "    \"valence 50.26%, energy 51.56%, danceability 53.12%\",\n",
    "    \"valence 86.46%, energy 86.72%, danceability 82.55%\",\n",
    "    \"valence 44.79%, energy 47.66%, danceability 55.73%\",\n",
    "    \"valence 36.98%, energy 44.53%, danceability 45.57%\",\n",
    "    \"valence 76.56%, energy 65.89%, danceability 69.01%\"\n",
    "]\n",
    "\n",
    "bert_list_acc = [\n",
    "    \"valence 46.88%, energy 46.09%, danceability 61.46%\",\n",
    "    \"valence 77.60%, energy 73.96%, danceability 81.51%\",\n",
    "    \"valence 45.57%, energy 52.08%, danceability 64.06%\",\n",
    "    \"valence 60.68%, energy 52.60%, danceability 59.90%\",\n",
    "    \"valence 69.01%, energy 72.92%, danceability 76.82%\",\n",
    "    \"valence 83.07%, energy 85.42%, danceability 84.38%\",\n",
    "    \"valence 69.53%, energy 60.94%, danceability 67.97%\",\n",
    "    \"valence 77.60%, energy 66.15%, danceability 63.54%\",\n",
    "    \"valence 64.32%, energy 73.18%, danceability 83.07%\",\n",
    "    \"valence 40.62%, energy 45.31%, danceability 47.14%\"\n",
    "]\n",
    "\n",
    "bert_numeric_acc = [\n",
    "    [float(value.split('%')[0].split(' ')[-1]) for value in row.split(', ')]\n",
    "    for row in bert_list_acc\n",
    "]\n",
    "\n",
    "roberta_numeric_acc = [\n",
    "    [float(value.split('%')[0].split(' ')[-1]) for value in row.split(', ')]\n",
    "    for row in roberta_list_acc\n",
    "]\n",
    "\n",
    "bert_valence_values = [val[0] for val in bert_numeric_acc]\n",
    "bert_energy_values = [val[1] for val in bert_numeric_acc]\n",
    "bert_danceability_values = [val[2] for val in bert_numeric_acc]\n",
    "\n",
    "roberta_valence_values = [val[0] for val in roberta_numeric_acc]\n",
    "roberta_energy_values = [val[1] for val in roberta_numeric_acc]\n",
    "roberta_danceability_values = [val[2] for val in roberta_numeric_acc]\n",
    "\n",
    "def sum_acc(a_list):\n",
    "    bert_valence_values, bert_energy_values, bert_danceability_values = a_list\n",
    "    average_values = []\n",
    "    for i in range(len(bert_valence_values)):\n",
    "        valence = bert_valence_values[i]\n",
    "        energy = bert_energy_values[i]\n",
    "        danceability = bert_danceability_values[i]\n",
    "        average = round((valence + energy + danceability) / 3, 2)\n",
    "        average_values.append(average)\n",
    "    return average_values\n",
    "\n",
    "bert_average_values = sum_acc([bert_valence_values, bert_energy_values, bert_danceability_values])\n",
    "roberta_average_values = sum_acc([roberta_valence_values, roberta_energy_values, roberta_danceability_values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dnn_accuracy, lstm_accuracy, cnn_accuracy = var_sum(all_model_metrics, acc_list)\n",
    "box_plot_train_accuracy = [dnn_accuracy, lstm_accuracy, cnn_accuracy, bert_average_values, roberta_average_values]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "box = ax.boxplot(box_plot_train_accuracy, vert=True, patch_artist=True)\n",
    "\n",
    "# Customize the appearance\n",
    "ax.set_title('Average Accuracy of Different Models')\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Percentage Accuracy (%)')\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "ax.set_xticklabels(['DNN', 'Bi-LSTM', 'CNN', 'BERT', 'RoBERTa'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
