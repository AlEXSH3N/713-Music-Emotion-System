{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras_tuner import RandomSearch, HyperParameters, Objective\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, Callback\n",
    "from transformers import BertTokenizer, TFBertModel, get_linear_schedule_with_warmup, WarmUp, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解压 cleaned_lyrics.zip 文件\n",
    "with zipfile.ZipFile('sampled.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('sampled')\n",
    "\n",
    "# 获取所有歌词文件的路径\n",
    "lyrics_files = {os.path.splitext(f)[0]: os.path.join('sampled', f) for f in os.listdir('sampled')}\n",
    "\n",
    "# 读取 filtered_dataset.csv 文件\n",
    "data = pd.read_csv('sampled_dataset.csv')\n",
    "\n",
    "def read_lyrics(record_id):\n",
    "    file_path = lyrics_files.get(str(record_id))\n",
    "    if file_path and os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    return ''\n",
    "\n",
    "# 读取歌词并添加到数据框中\n",
    "data['lyrics'] = data['record_id'].apply(read_lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>record_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>valence_bin</th>\n",
       "      <th>energy_bin</th>\n",
       "      <th>danceability_bin</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1458</td>\n",
       "      <td>2834</td>\n",
       "      <td>2834</td>\n",
       "      <td>20097</td>\n",
       "      <td>4b98LXC0QUWGBteJ5uwVQY</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Summer Music Festival Hits</td>\n",
       "      <td>Boss Bitch</td>\n",
       "      <td>0</td>\n",
       "      <td>134239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.575</td>\n",
       "      <td>125.993</td>\n",
       "      <td>4</td>\n",
       "      <td>dance</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>mmm not tryna ah not tryna not tryna yeah not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1557</td>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "      <td>22816</td>\n",
       "      <td>58Z83tSbShyHxCwqTCE8M6</td>\n",
       "      <td>Goatwhore</td>\n",
       "      <td>Vengeful Ascension</td>\n",
       "      <td>Under the Flesh, Into the Soul</td>\n",
       "      <td>21</td>\n",
       "      <td>273266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.347</td>\n",
       "      <td>170.015</td>\n",
       "      <td>4</td>\n",
       "      <td>death-metal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>world grave apathetic cold selfish prison cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>3220</td>\n",
       "      <td>0AOmbw8AwDnwXhHC3OhdVB</td>\n",
       "      <td>Thousand Foot Krutch</td>\n",
       "      <td>The End Is Where We Begin</td>\n",
       "      <td>Courtesy Call</td>\n",
       "      <td>72</td>\n",
       "      <td>236898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.445</td>\n",
       "      <td>164.079</td>\n",
       "      <td>4</td>\n",
       "      <td>alternative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hey comes danger club get started man not gonn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>989</td>\n",
       "      <td>2054</td>\n",
       "      <td>2054</td>\n",
       "      <td>14581</td>\n",
       "      <td>5Jaj6nLjHCizmcPddJLO3k</td>\n",
       "      <td>Blippi</td>\n",
       "      <td>Blippi Tunes, Vol. 2: Machines (Music for Todd...</td>\n",
       "      <td>The Train Song</td>\n",
       "      <td>53</td>\n",
       "      <td>207428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.662</td>\n",
       "      <td>139.895</td>\n",
       "      <td>4</td>\n",
       "      <td>children</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>choo choo comes train choo choo comes train ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>383</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>3717</td>\n",
       "      <td>2oaK4JLVnmRGIO9ytBE1bt</td>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>The Getaway</td>\n",
       "      <td>Dark Necessities</td>\n",
       "      <td>74</td>\n",
       "      <td>302000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.197</td>\n",
       "      <td>91.959</td>\n",
       "      <td>4</td>\n",
       "      <td>alternative</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>comin light day got many moons deep play keep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>658</td>\n",
       "      <td>1229</td>\n",
       "      <td>1229</td>\n",
       "      <td>8662</td>\n",
       "      <td>3hSy2AUoElgIk6fjhYnRH3</td>\n",
       "      <td>Elvin Bishop</td>\n",
       "      <td>Sure Feels Good: The Best Of Elvin Bishop</td>\n",
       "      <td>Fooled Around And Fell In Love</td>\n",
       "      <td>57</td>\n",
       "      <td>276933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.610</td>\n",
       "      <td>113.463</td>\n",
       "      <td>3</td>\n",
       "      <td>blues</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>million girls love em leave em alone not care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>5818</td>\n",
       "      <td>10682</td>\n",
       "      <td>10682</td>\n",
       "      <td>113479</td>\n",
       "      <td>5ELZpvTDGorz9BIE9zaBoZ</td>\n",
       "      <td>Tenth Avenue North</td>\n",
       "      <td>Followers</td>\n",
       "      <td>I Have This Hope</td>\n",
       "      <td>52</td>\n",
       "      <td>204800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.110</td>\n",
       "      <td>108.009</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>walk great unknown questions come questions go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>265</td>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "      <td>2185</td>\n",
       "      <td>3mJV4kByjmgU3ubU7JPp9W</td>\n",
       "      <td>Marilyn Manson</td>\n",
       "      <td>Halloween 2022</td>\n",
       "      <td>You And Me And The Devil Makes 3</td>\n",
       "      <td>0</td>\n",
       "      <td>264266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.399</td>\n",
       "      <td>128.021</td>\n",
       "      <td>4</td>\n",
       "      <td>alt-rock</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>like rolling stone hill hades want lie gonna l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>5031</td>\n",
       "      <td>9325</td>\n",
       "      <td>9325</td>\n",
       "      <td>94717</td>\n",
       "      <td>5xUpsNCW71S58c8TycsqNa</td>\n",
       "      <td>Ollie</td>\n",
       "      <td>Sunsets &amp; Goodbyes</td>\n",
       "      <td>what if</td>\n",
       "      <td>39</td>\n",
       "      <td>173615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.283</td>\n",
       "      <td>146.006</td>\n",
       "      <td>4</td>\n",
       "      <td>sad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yeah call one day everything yeah call next no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>5723</td>\n",
       "      <td>10541</td>\n",
       "      <td>10541</td>\n",
       "      <td>107316</td>\n",
       "      <td>7skyR8nK3vnDikYFBoUVw6</td>\n",
       "      <td>Laura Branigan</td>\n",
       "      <td>Self Control (Expanded)</td>\n",
       "      <td>Self Control - Extended Version</td>\n",
       "      <td>52</td>\n",
       "      <td>304893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.803</td>\n",
       "      <td>106.378</td>\n",
       "      <td>4</td>\n",
       "      <td>synth-pop</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>oh night world city light painted girl day not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.2  Unnamed: 0.1  record_id  Unnamed: 0   \n",
       "0            1458          2834       2834       20097  \\\n",
       "1            1557          2967       2967       22816   \n",
       "2             425           616        616        3220   \n",
       "3             989          2054       2054       14581   \n",
       "4             383           562        562        3717   \n",
       "..            ...           ...        ...         ...   \n",
       "595           658          1229       1229        8662   \n",
       "596          5818         10682      10682      113479   \n",
       "597           265           426        426        2185   \n",
       "598          5031          9325       9325       94717   \n",
       "599          5723         10541      10541      107316   \n",
       "\n",
       "                   track_id                artists   \n",
       "0    4b98LXC0QUWGBteJ5uwVQY               Doja Cat  \\\n",
       "1    58Z83tSbShyHxCwqTCE8M6              Goatwhore   \n",
       "2    0AOmbw8AwDnwXhHC3OhdVB   Thousand Foot Krutch   \n",
       "3    5Jaj6nLjHCizmcPddJLO3k                 Blippi   \n",
       "4    2oaK4JLVnmRGIO9ytBE1bt  Red Hot Chili Peppers   \n",
       "..                      ...                    ...   \n",
       "595  3hSy2AUoElgIk6fjhYnRH3           Elvin Bishop   \n",
       "596  5ELZpvTDGorz9BIE9zaBoZ     Tenth Avenue North   \n",
       "597  3mJV4kByjmgU3ubU7JPp9W         Marilyn Manson   \n",
       "598  5xUpsNCW71S58c8TycsqNa                  Ollie   \n",
       "599  7skyR8nK3vnDikYFBoUVw6         Laura Branigan   \n",
       "\n",
       "                                            album_name   \n",
       "0                           Summer Music Festival Hits  \\\n",
       "1                                   Vengeful Ascension   \n",
       "2                            The End Is Where We Begin   \n",
       "3    Blippi Tunes, Vol. 2: Machines (Music for Todd...   \n",
       "4                                          The Getaway   \n",
       "..                                                 ...   \n",
       "595          Sure Feels Good: The Best Of Elvin Bishop   \n",
       "596                                          Followers   \n",
       "597                                     Halloween 2022   \n",
       "598                                 Sunsets & Goodbyes   \n",
       "599                            Self Control (Expanded)   \n",
       "\n",
       "                           track_name  popularity  duration_ms  ...   \n",
       "0                          Boss Bitch           0       134239  ...  \\\n",
       "1      Under the Flesh, Into the Soul          21       273266  ...   \n",
       "2                       Courtesy Call          72       236898  ...   \n",
       "3                      The Train Song          53       207428  ...   \n",
       "4                    Dark Necessities          74       302000  ...   \n",
       "..                                ...         ...          ...  ...   \n",
       "595    Fooled Around And Fell In Love          57       276933  ...   \n",
       "596                  I Have This Hope          52       204800  ...   \n",
       "597  You And Me And The Devil Makes 3           0       264266  ...   \n",
       "598                           what if          39       173615  ...   \n",
       "599   Self Control - Extended Version          52       304893  ...   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  time_signature   \n",
       "0            0.000000    0.2030    0.575  125.993               4  \\\n",
       "1            0.110000    0.1070    0.347  170.015               4   \n",
       "2            0.000000    0.0822    0.445  164.079               4   \n",
       "3            0.000019    0.3250    0.662  139.895               4   \n",
       "4            0.019900    0.1100    0.197   91.959               4   \n",
       "..                ...       ...      ...      ...             ...   \n",
       "595          0.080500    0.0953    0.610  113.463               3   \n",
       "596          0.000000    0.1890    0.110  108.009               4   \n",
       "597          0.834000    0.2030    0.399  128.021               4   \n",
       "598          0.000627    0.0723    0.283  146.006               4   \n",
       "599          0.009970    0.1880    0.803  106.378               4   \n",
       "\n",
       "     track_genre  valence_bin  energy_bin  danceability_bin   \n",
       "0          dance            1           2                 2  \\\n",
       "1    death-metal            1           2                 0   \n",
       "2    alternative            1           1                 1   \n",
       "3       children            2           1                 2   \n",
       "4    alternative            0           2                 2   \n",
       "..           ...          ...         ...               ...   \n",
       "595        blues            1           1                 1   \n",
       "596  world-music            0           1                 1   \n",
       "597     alt-rock            1           2                 1   \n",
       "598          sad            0           0                 2   \n",
       "599    synth-pop            2           2                 2   \n",
       "\n",
       "                                                lyrics  \n",
       "0    mmm not tryna ah not tryna not tryna yeah not ...  \n",
       "1    world grave apathetic cold selfish prison cove...  \n",
       "2    hey comes danger club get started man not gonn...  \n",
       "3    choo choo comes train choo choo comes train ro...  \n",
       "4    comin light day got many moons deep play keep ...  \n",
       "..                                                 ...  \n",
       "595  million girls love em leave em alone not care ...  \n",
       "596  walk great unknown questions come questions go...  \n",
       "597  like rolling stone hill hades want lie gonna l...  \n",
       "598  yeah call one day everything yeah call next no...  \n",
       "599  oh night world city light painted girl day not...  \n",
       "\n",
       "[600 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyrics_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>record_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>valence_bin</th>\n",
       "      <th>energy_bin</th>\n",
       "      <th>danceability_bin</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1458</td>\n",
       "      <td>2834</td>\n",
       "      <td>2834</td>\n",
       "      <td>20097</td>\n",
       "      <td>4b98LXC0QUWGBteJ5uwVQY</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Summer Music Festival Hits</td>\n",
       "      <td>Boss Bitch</td>\n",
       "      <td>0</td>\n",
       "      <td>134239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.575</td>\n",
       "      <td>125.993</td>\n",
       "      <td>4</td>\n",
       "      <td>dance</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>mmm not tryna ah not tryna not tryna yeah not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1557</td>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "      <td>22816</td>\n",
       "      <td>58Z83tSbShyHxCwqTCE8M6</td>\n",
       "      <td>Goatwhore</td>\n",
       "      <td>Vengeful Ascension</td>\n",
       "      <td>Under the Flesh, Into the Soul</td>\n",
       "      <td>21</td>\n",
       "      <td>273266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.347</td>\n",
       "      <td>170.015</td>\n",
       "      <td>4</td>\n",
       "      <td>death-metal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>world grave apathetic cold selfish prison cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>3220</td>\n",
       "      <td>0AOmbw8AwDnwXhHC3OhdVB</td>\n",
       "      <td>Thousand Foot Krutch</td>\n",
       "      <td>The End Is Where We Begin</td>\n",
       "      <td>Courtesy Call</td>\n",
       "      <td>72</td>\n",
       "      <td>236898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.445</td>\n",
       "      <td>164.079</td>\n",
       "      <td>4</td>\n",
       "      <td>alternative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hey comes danger club get started man not gonn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>989</td>\n",
       "      <td>2054</td>\n",
       "      <td>2054</td>\n",
       "      <td>14581</td>\n",
       "      <td>5Jaj6nLjHCizmcPddJLO3k</td>\n",
       "      <td>Blippi</td>\n",
       "      <td>Blippi Tunes, Vol. 2: Machines (Music for Todd...</td>\n",
       "      <td>The Train Song</td>\n",
       "      <td>53</td>\n",
       "      <td>207428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.662</td>\n",
       "      <td>139.895</td>\n",
       "      <td>4</td>\n",
       "      <td>children</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>choo choo comes train choo choo comes train ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>383</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>3717</td>\n",
       "      <td>2oaK4JLVnmRGIO9ytBE1bt</td>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>The Getaway</td>\n",
       "      <td>Dark Necessities</td>\n",
       "      <td>74</td>\n",
       "      <td>302000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.197</td>\n",
       "      <td>91.959</td>\n",
       "      <td>4</td>\n",
       "      <td>alternative</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>comin light day got many moons deep play keep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>658</td>\n",
       "      <td>1229</td>\n",
       "      <td>1229</td>\n",
       "      <td>8662</td>\n",
       "      <td>3hSy2AUoElgIk6fjhYnRH3</td>\n",
       "      <td>Elvin Bishop</td>\n",
       "      <td>Sure Feels Good: The Best Of Elvin Bishop</td>\n",
       "      <td>Fooled Around And Fell In Love</td>\n",
       "      <td>57</td>\n",
       "      <td>276933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.610</td>\n",
       "      <td>113.463</td>\n",
       "      <td>3</td>\n",
       "      <td>blues</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>million girls love em leave em alone not care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>5818</td>\n",
       "      <td>10682</td>\n",
       "      <td>10682</td>\n",
       "      <td>113479</td>\n",
       "      <td>5ELZpvTDGorz9BIE9zaBoZ</td>\n",
       "      <td>Tenth Avenue North</td>\n",
       "      <td>Followers</td>\n",
       "      <td>I Have This Hope</td>\n",
       "      <td>52</td>\n",
       "      <td>204800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.110</td>\n",
       "      <td>108.009</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>walk great unknown questions come questions go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>265</td>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "      <td>2185</td>\n",
       "      <td>3mJV4kByjmgU3ubU7JPp9W</td>\n",
       "      <td>Marilyn Manson</td>\n",
       "      <td>Halloween 2022</td>\n",
       "      <td>You And Me And The Devil Makes 3</td>\n",
       "      <td>0</td>\n",
       "      <td>264266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.399</td>\n",
       "      <td>128.021</td>\n",
       "      <td>4</td>\n",
       "      <td>alt-rock</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>like rolling stone hill hades want lie gonna l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>5031</td>\n",
       "      <td>9325</td>\n",
       "      <td>9325</td>\n",
       "      <td>94717</td>\n",
       "      <td>5xUpsNCW71S58c8TycsqNa</td>\n",
       "      <td>Ollie</td>\n",
       "      <td>Sunsets &amp; Goodbyes</td>\n",
       "      <td>what if</td>\n",
       "      <td>39</td>\n",
       "      <td>173615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.283</td>\n",
       "      <td>146.006</td>\n",
       "      <td>4</td>\n",
       "      <td>sad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yeah call one day everything yeah call next no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>5723</td>\n",
       "      <td>10541</td>\n",
       "      <td>10541</td>\n",
       "      <td>107316</td>\n",
       "      <td>7skyR8nK3vnDikYFBoUVw6</td>\n",
       "      <td>Laura Branigan</td>\n",
       "      <td>Self Control (Expanded)</td>\n",
       "      <td>Self Control - Extended Version</td>\n",
       "      <td>52</td>\n",
       "      <td>304893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.803</td>\n",
       "      <td>106.378</td>\n",
       "      <td>4</td>\n",
       "      <td>synth-pop</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>oh night world city light painted girl day not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.2  Unnamed: 0.1  record_id  Unnamed: 0   \n",
       "0            1458          2834       2834       20097  \\\n",
       "1            1557          2967       2967       22816   \n",
       "2             425           616        616        3220   \n",
       "3             989          2054       2054       14581   \n",
       "4             383           562        562        3717   \n",
       "..            ...           ...        ...         ...   \n",
       "595           658          1229       1229        8662   \n",
       "596          5818         10682      10682      113479   \n",
       "597           265           426        426        2185   \n",
       "598          5031          9325       9325       94717   \n",
       "599          5723         10541      10541      107316   \n",
       "\n",
       "                   track_id                artists   \n",
       "0    4b98LXC0QUWGBteJ5uwVQY               Doja Cat  \\\n",
       "1    58Z83tSbShyHxCwqTCE8M6              Goatwhore   \n",
       "2    0AOmbw8AwDnwXhHC3OhdVB   Thousand Foot Krutch   \n",
       "3    5Jaj6nLjHCizmcPddJLO3k                 Blippi   \n",
       "4    2oaK4JLVnmRGIO9ytBE1bt  Red Hot Chili Peppers   \n",
       "..                      ...                    ...   \n",
       "595  3hSy2AUoElgIk6fjhYnRH3           Elvin Bishop   \n",
       "596  5ELZpvTDGorz9BIE9zaBoZ     Tenth Avenue North   \n",
       "597  3mJV4kByjmgU3ubU7JPp9W         Marilyn Manson   \n",
       "598  5xUpsNCW71S58c8TycsqNa                  Ollie   \n",
       "599  7skyR8nK3vnDikYFBoUVw6         Laura Branigan   \n",
       "\n",
       "                                            album_name   \n",
       "0                           Summer Music Festival Hits  \\\n",
       "1                                   Vengeful Ascension   \n",
       "2                            The End Is Where We Begin   \n",
       "3    Blippi Tunes, Vol. 2: Machines (Music for Todd...   \n",
       "4                                          The Getaway   \n",
       "..                                                 ...   \n",
       "595          Sure Feels Good: The Best Of Elvin Bishop   \n",
       "596                                          Followers   \n",
       "597                                     Halloween 2022   \n",
       "598                                 Sunsets & Goodbyes   \n",
       "599                            Self Control (Expanded)   \n",
       "\n",
       "                           track_name  popularity  duration_ms  ...   \n",
       "0                          Boss Bitch           0       134239  ...  \\\n",
       "1      Under the Flesh, Into the Soul          21       273266  ...   \n",
       "2                       Courtesy Call          72       236898  ...   \n",
       "3                      The Train Song          53       207428  ...   \n",
       "4                    Dark Necessities          74       302000  ...   \n",
       "..                                ...         ...          ...  ...   \n",
       "595    Fooled Around And Fell In Love          57       276933  ...   \n",
       "596                  I Have This Hope          52       204800  ...   \n",
       "597  You And Me And The Devil Makes 3           0       264266  ...   \n",
       "598                           what if          39       173615  ...   \n",
       "599   Self Control - Extended Version          52       304893  ...   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  time_signature   \n",
       "0            0.000000    0.2030    0.575  125.993               4  \\\n",
       "1            0.110000    0.1070    0.347  170.015               4   \n",
       "2            0.000000    0.0822    0.445  164.079               4   \n",
       "3            0.000019    0.3250    0.662  139.895               4   \n",
       "4            0.019900    0.1100    0.197   91.959               4   \n",
       "..                ...       ...      ...      ...             ...   \n",
       "595          0.080500    0.0953    0.610  113.463               3   \n",
       "596          0.000000    0.1890    0.110  108.009               4   \n",
       "597          0.834000    0.2030    0.399  128.021               4   \n",
       "598          0.000627    0.0723    0.283  146.006               4   \n",
       "599          0.009970    0.1880    0.803  106.378               4   \n",
       "\n",
       "     track_genre  valence_bin  energy_bin  danceability_bin   \n",
       "0          dance            1           2                 2  \\\n",
       "1    death-metal            1           2                 0   \n",
       "2    alternative            1           1                 1   \n",
       "3       children            2           1                 2   \n",
       "4    alternative            0           2                 2   \n",
       "..           ...          ...         ...               ...   \n",
       "595        blues            1           1                 1   \n",
       "596  world-music            0           1                 1   \n",
       "597     alt-rock            1           2                 1   \n",
       "598          sad            0           0                 2   \n",
       "599    synth-pop            2           2                 2   \n",
       "\n",
       "                                                lyrics  \n",
       "0    mmm not tryna ah not tryna not tryna yeah not ...  \n",
       "1    world grave apathetic cold selfish prison cove...  \n",
       "2    hey comes danger club get started man not gonn...  \n",
       "3    choo choo comes train choo choo comes train ro...  \n",
       "4    comin light day got many moons deep play keep ...  \n",
       "..                                                 ...  \n",
       "595  million girls love em leave em alone not care ...  \n",
       "596  walk great unknown questions come questions go...  \n",
       "597  like rolling stone hill hades want lie gonna l...  \n",
       "598  yeah call one day everything yeah call next no...  \n",
       "599  oh night world city light painted girl day not...  \n",
       "\n",
       "[600 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Tokenizer 处理文本\n",
    "max_words = 5000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['lyrics'])\n",
    "sequences = tokenizer.texts_to_sequences(data['lyrics'])\n",
    "X_lyrics = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# 准备标签\n",
    "y_valence = to_categorical(data['valence_bin'].values)\n",
    "y_energy = to_categorical(data['energy_bin'].values)\n",
    "y_danceability = to_categorical(data['danceability_bin'].values)\n",
    "\n",
    "# 拆分数据集\n",
    "X_train_val, X_test, y_train_val_valence, y_test_valence, y_train_val_energy, y_test_energy, y_train_val_danceability, y_test_danceability = train_test_split(\n",
    "    X_lyrics, y_valence, y_energy, y_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train_valence, y_val_valence, y_train_energy, y_val_energy, y_train_danceability, y_val_danceability = train_test_split(\n",
    "    X_train_val, y_train_val_valence, y_train_val_energy, y_train_val_danceability, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9,   80,   77, ...,  718, 3619,   32],\n",
       "       [  28,  344,  780, ...,  344,  780,   32],\n",
       "       [  77,  609,  198, ...,  609,  198,   32],\n",
       "       ...,\n",
       "       [   1,    1,  433, ...,   28,   44,   32],\n",
       "       [ 653, 1380,  591, ...,    4,  203,   32],\n",
       "       [  58,  135,   13, ..., 1744,  313,   32]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 03s]\n",
      "val_valence_output_accuracy: 0.5\n",
      "\n",
      "Best val_valence_output_accuracy So Far: 0.5\n",
      "Total elapsed time: 00h 00m 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_dim': 6000, 'output_dim': 32, 'num_layers': 2, 'units_layer1': 320, 'dropout_layer1': 0.1, 'units_final': 320, 'l2_regularization': 0.0, 'kernel_initializer': 'he_normal', 'optimizer': 'adam', 'learning_rate': 1e-05, 'units_layer2': 160, 'dropout_layer2': 0.2, 'units_layer3': 256, 'dropout_layer3': 0.4, 'units_layer4': 288, 'dropout_layer4': 0.0}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2663 - valence_output_loss: 1.0943 - energy_output_loss: 1.0905 - danceability_output_loss: 1.0815 - valence_output_accuracy: 0.4083 - energy_output_accuracy: 0.4500 - danceability_output_accuracy: 0.4167\n",
      "Test Loss: 3.2663047313690186, valence_output_loss: 1.094298005104065, energy_output_loss: 1.0904593467712402, danceability_output_loss: 1.081547498703003, Test Accuracy Valence: 0.40833333134651184, Test Accuracy Energy: 0.44999998807907104, Test Accuracy Danceability: 0.4166666567325592\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch, HyperParameters, Objective\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# 构建模型函数\n",
    "def build_model(hp):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=hp.Int('input_dim', min_value=1000, max_value=10000, step=1000),\n",
    "                  output_dim=hp.Int('output_dim', min_value=32, max_value=128, step=32),\n",
    "                  input_length=max_len)(inputs)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=5, step=1)\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            x = Dense(units=hp.Int(f'units_layer{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        else:\n",
    "            x = Dense(units=hp.Int(f'units_layer{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        x = Dropout(rate=hp.Float(f'dropout_layer{i+1}', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
    "\n",
    "    x = Dense(units=hp.Int('units_final', min_value=32, max_value=512, step=32),\n",
    "              activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(hp.Choice('l2_regularization', values=[0.0, 1e-4, 1e-3])),\n",
    "              kernel_initializer=hp.Choice('kernel_initializer', values=['glorot_uniform', 'he_normal']))(x)\n",
    "\n",
    "    \n",
    "    output_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(x)\n",
    "    output_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(x)\n",
    "    output_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[output_valence, output_energy, output_danceability])\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# 超参数调优\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=Objective('val_valence_output_accuracy', direction='max'),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='dnn_mood_detection_600'\n",
    ")\n",
    "\n",
    "# 启动调优过程\n",
    "tuner.search(X_train, [y_train_valence, y_train_energy, y_train_danceability], \n",
    "             epochs=20, \n",
    "             validation_data=(X_val, [y_val_valence, y_val_energy, y_val_danceability]), \n",
    "             callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# 评估模型\n",
    "\n",
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2663 - valence_output_loss: 1.0943 - energy_output_loss: 1.0905 - danceability_output_loss: 1.0815 - valence_output_accuracy: 0.4083 - energy_output_accuracy: 0.4500 - danceability_output_accuracy: 0.4167\n",
      "[3.2663047313690186, 1.094298005104065, 1.0904593467712402, 1.081547498703003, 0.40833333134651184, 0.44999998807907104, 0.4166666567325592]\n"
     ]
    }
   ],
   "source": [
    "metrics = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "#print(f'Test Loss: {loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 02s]\n",
      "val_valence_output_accuracy: 0.5\n",
      "\n",
      "Best val_valence_output_accuracy So Far: 0.5625\n",
      "Total elapsed time: 00h 00m 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_output_dim': 128, 'filters': 96, 'kernel_size': 7, 'pool_size': 2, 'num_layers': 1, 'dense_units_1': 192, 'dropout_1': 0.1, 'optimizer': 'adam', 'learning_rate': 0.001, 'dense_units_2': 192, 'dropout_2': 0.0, 'dense_units_3': 320, 'dropout_3': 0.30000000000000004}\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.1327 - valence_output_loss: 1.0610 - energy_output_loss: 1.0361 - danceability_output_loss: 1.0356 - valence_output_accuracy: 0.4167 - energy_output_accuracy: 0.4583 - danceability_output_accuracy: 0.4583\n",
      "Test Loss: 3.132678270339966, valence_output_loss: 1.0609853267669678, energy_output_loss: 1.0360546112060547, danceability_output_loss: 1.0356380939483643, Test Accuracy Valence: 0.4166666567325592, Test Accuracy Energy: 0.4583333432674408, Test Accuracy Danceability: 0.4583333432674408\n"
     ]
    }
   ],
   "source": [
    "# 构建 CNN 模型函数\n",
    "def build_cnn_model(hp):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=max_words, output_dim=hp.Int('embedding_output_dim', min_value=32, max_value=128, step=32), input_length=max_len)(inputs)\n",
    "    x = tf.keras.layers.Conv1D(filters=hp.Int('filters', min_value=32, max_value=128, step=32), kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=2), activation='relu')(x)\n",
    "    x = tf.keras.layers.AveragePooling1D(pool_size=hp.Int('pool_size', min_value=2, max_value=5, step=1))(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
    "    for i in range(num_layers):\n",
    "        x = Dense(units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        x = Dropout(rate=hp.Float(f'dropout_{i+1}', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    output_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(x)\n",
    "    output_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(x)\n",
    "    output_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[output_valence, output_energy, output_danceability])\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# 超参数调优\n",
    "tuner = RandomSearch(\n",
    "    build_cnn_model,\n",
    "    objective=Objective('val_valence_output_accuracy', direction='max'),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='cnn_mood_detection_600'\n",
    ")\n",
    "\n",
    "# 启动调优过程\n",
    "tuner.search(X_train, [y_train_valence, y_train_energy, y_train_danceability], \n",
    "             epochs=20, \n",
    "             validation_data=(X_val, [y_val_valence, y_val_energy, y_val_danceability]), \n",
    "             callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# 评估模型\n",
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 123s 5s/step - loss: 3.6207 - valence_output_loss: 1.1824 - energy_output_loss: 1.1173 - danceability_output_loss: 1.1412 - valence_output_accuracy: 0.3385 - energy_output_accuracy: 0.3958 - danceability_output_accuracy: 0.3724 - val_loss: 3.4535 - val_valence_output_loss: 1.0734 - val_energy_output_loss: 1.1222 - val_danceability_output_loss: 1.0782 - val_valence_output_accuracy: 0.3958 - val_energy_output_accuracy: 0.4688 - val_danceability_output_accuracy: 0.4271\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 118s 5s/step - loss: 3.3782 - valence_output_loss: 1.1062 - energy_output_loss: 1.0455 - danceability_output_loss: 1.0469 - valence_output_accuracy: 0.4089 - energy_output_accuracy: 0.4479 - danceability_output_accuracy: 0.4714 - val_loss: 3.4023 - val_valence_output_loss: 1.0577 - val_energy_output_loss: 1.0608 - val_danceability_output_loss: 1.1041 - val_valence_output_accuracy: 0.4375 - val_energy_output_accuracy: 0.4375 - val_danceability_output_accuracy: 0.3750\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 121s 5s/step - loss: 3.2260 - valence_output_loss: 1.0516 - energy_output_loss: 1.0232 - danceability_output_loss: 0.9717 - valence_output_accuracy: 0.4401 - energy_output_accuracy: 0.4688 - danceability_output_accuracy: 0.5234 - val_loss: 3.3491 - val_valence_output_loss: 1.0447 - val_energy_output_loss: 1.0643 - val_danceability_output_loss: 1.0605 - val_valence_output_accuracy: 0.4688 - val_energy_output_accuracy: 0.4583 - val_danceability_output_accuracy: 0.4479\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 121s 5s/step - loss: 3.0481 - valence_output_loss: 1.0064 - energy_output_loss: 0.9655 - danceability_output_loss: 0.8967 - valence_output_accuracy: 0.4870 - energy_output_accuracy: 0.5391 - danceability_output_accuracy: 0.5938 - val_loss: 3.2812 - val_valence_output_loss: 1.0242 - val_energy_output_loss: 1.0156 - val_danceability_output_loss: 1.0620 - val_valence_output_accuracy: 0.5000 - val_energy_output_accuracy: 0.5208 - val_danceability_output_accuracy: 0.4479\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 120s 5s/step - loss: 2.8380 - valence_output_loss: 0.9567 - energy_output_loss: 0.9072 - danceability_output_loss: 0.7945 - valence_output_accuracy: 0.5286 - energy_output_accuracy: 0.5807 - danceability_output_accuracy: 0.6536 - val_loss: 3.3070 - val_valence_output_loss: 1.0159 - val_energy_output_loss: 1.0321 - val_danceability_output_loss: 1.0795 - val_valence_output_accuracy: 0.4375 - val_energy_output_accuracy: 0.5208 - val_danceability_output_accuracy: 0.4479\n",
      "4/4 [==============================] - 12s 3s/step - loss: 3.2246 - valence_output_loss: 1.0353 - energy_output_loss: 1.0656 - danceability_output_loss: 0.9442 - valence_output_accuracy: 0.4583 - energy_output_accuracy: 0.4167 - danceability_output_accuracy: 0.5083\n",
      "Test Loss: 3.224637508392334, valence_output_loss: 1.0352818965911865, energy_output_loss: 1.06563138961792, danceability_output_loss: 0.9442141652107239\n",
      "Test Accuracy Valence: 0.4583333432674408, Test Accuracy Energy: 0.4166666567325592, Test Accuracy Danceability: 0.5083333253860474\n"
     ]
    }
   ],
   "source": [
    "# 拆分数据集\n",
    "X_train_val, X_test, y_train_val_valence, y_test_valence, y_train_val_energy, y_test_energy, y_train_val_danceability, y_test_danceability = train_test_split(\n",
    "    data['lyrics'], y_valence, y_energy, y_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train_valence, y_val_valence, y_train_energy, y_val_energy, y_train_danceability, y_val_danceability = train_test_split(\n",
    "    X_train_val, y_train_val_valence, y_train_val_energy, y_train_val_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用 BertTokenizer 和 TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize(sentences, tokenizer, max_len=128):\n",
    "    input_ids, attention_masks = [], []\n",
    "    for sent in sentences:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text=sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids), np.array(attention_masks)\n",
    "\n",
    "max_len = 128\n",
    "\n",
    "X_train_input_ids, X_train_attention_masks = tokenize(X_train, tokenizer, max_len)\n",
    "X_val_input_ids, X_val_attention_masks = tokenize(X_val, tokenizer, max_len)\n",
    "X_test_input_ids, X_test_attention_masks = tokenize(X_test, tokenizer, max_len)\n",
    "\n",
    "# 构建BERT模型\n",
    "def build_bert_model():\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]\n",
    "    cls_token = bert_output[:, 0, :]\n",
    "    \n",
    "    # 添加 Dropout 和 L2 正则化\n",
    "    cls_token = Dropout(0.3)(cls_token)\n",
    "\n",
    "    dense_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[dense_valence, dense_energy, dense_danceability])\n",
    "    return model\n",
    "\n",
    "# 构建并训练模型\n",
    "model = build_bert_model()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# 设置学习率调度器\n",
    "num_train_steps = len(X_train_input_ids) // 16 * 5  # 数据量 / batch_size * epochs\n",
    "num_warmup_steps = num_train_steps // 10  # 通常设置为训练步骤的10%\n",
    "\n",
    "optimizer = Adam(learning_rate=tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=2e-5,\n",
    "    decay_steps=num_train_steps,\n",
    "    end_learning_rate=0.0\n",
    "))\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss={'valence_output': 'categorical_crossentropy', \n",
    "                    'energy_output': 'categorical_crossentropy', \n",
    "                    'danceability_output': 'categorical_crossentropy'},\n",
    "              metrics={'valence_output': 'accuracy', \n",
    "                       'energy_output': 'accuracy', \n",
    "                       'danceability_output': 'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_input_ids, X_train_attention_masks],\n",
    "    {'valence_output': y_train_valence, 'energy_output': y_train_energy, 'danceability_output': y_train_danceability},\n",
    "    validation_data=([X_val_input_ids, X_val_attention_masks], {'valence_output': y_val_valence, 'energy_output': y_val_energy, 'danceability_output': y_val_danceability}),\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = model.evaluate(\n",
    "    [X_test_input_ids, X_test_attention_masks], \n",
    "    [y_test_valence, y_test_energy, y_test_danceability]\n",
    ")\n",
    "\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}')\n",
    "print(f'Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have implemented lr and weight decay onto this, therefore it has warm up and decay now with l2 reg, and i only ran 5 epochs because its quite slow on my mac, I noticed the loss is still decreasing drastically, therefore i believe runing more epochs will eventually boost the acc by a lot, can you guys make it 10-15 epochs and test out whats going on at that. Thx, ill now push this version onto github."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
