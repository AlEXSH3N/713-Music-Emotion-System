{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras_tuner import RandomSearch, HyperParameters, Objective\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解压 cleaned_lyrics.zip 文件\n",
    "with zipfile.ZipFile('cleaned_lyrics.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('cleaned_lyrics')\n",
    "\n",
    "# 获取所有歌词文件的路径\n",
    "lyrics_files = {os.path.splitext(f)[0]: os.path.join('cleaned_lyrics', f) for f in os.listdir('cleaned_lyrics')}\n",
    "\n",
    "# 读取 filtered_dataset.csv 文件\n",
    "data = pd.read_csv('filtered_dataset.csv')\n",
    "\n",
    "def read_lyrics(record_id):\n",
    "    file_path = lyrics_files.get(str(record_id))\n",
    "    if file_path and os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    return ''\n",
    "\n",
    "# 读取歌词并添加到数据框中\n",
    "data['lyrics'] = data['record_id'].apply(read_lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>record_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>valence_bin</th>\n",
       "      <th>energy_bin</th>\n",
       "      <th>danceability_bin</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>740</td>\n",
       "      <td>1T7Tqsfkz0Ntbwta2hHebY</td>\n",
       "      <td>Days N Daze</td>\n",
       "      <td>Rogue Taxidermy</td>\n",
       "      <td>Fate of a Coward</td>\n",
       "      <td>28</td>\n",
       "      <td>175046</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.9430</td>\n",
       "      <td>123.094</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>mind seeping darkness pulse growing weaker mom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>513</td>\n",
       "      <td>27hFQQS3cVUmIK3ser5bpu</td>\n",
       "      <td>Colin &amp; Caroline</td>\n",
       "      <td>More Than Gravity</td>\n",
       "      <td>More Than Gravity</td>\n",
       "      <td>34</td>\n",
       "      <td>266078</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>110.969</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>simple explanation things feel one word tell t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>2PIlBukQ6limukVR8Ubb5o</td>\n",
       "      <td>Gabrielle Aplin</td>\n",
       "      <td>English Rain</td>\n",
       "      <td>Please Don't Say You Love Me</td>\n",
       "      <td>59</td>\n",
       "      <td>181400</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>85.994</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>summer comes winter fades not pressure not cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>899</td>\n",
       "      <td>4uPvXmXGjYOOqhbRMmS9XU</td>\n",
       "      <td>Grace Petrie</td>\n",
       "      <td>Queer As Folk</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>26</td>\n",
       "      <td>270920</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>125.642</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>gone lonesome road goes forever espresso shot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>549</td>\n",
       "      <td>2saK0E712wIB3Gf8QLuFYX</td>\n",
       "      <td>Get Dead</td>\n",
       "      <td>Dancing with the Curse</td>\n",
       "      <td>Nickel Plated</td>\n",
       "      <td>29</td>\n",
       "      <td>136815</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6540</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>179.920</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>nickel plated tooth briefcase hold breath poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>10802</td>\n",
       "      <td>10802</td>\n",
       "      <td>113500</td>\n",
       "      <td>2kDe0QRaCBKIh8QY64GDvK</td>\n",
       "      <td>Bethel Music;Jenn Johnson</td>\n",
       "      <td>We Will Not Be Shaken (Live)</td>\n",
       "      <td>In Over My Head (Crash Over Me) - Live</td>\n",
       "      <td>49</td>\n",
       "      <td>298681</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>141.800</td>\n",
       "      <td>3</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>come place life full satisfied longing feel he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5897</th>\n",
       "      <td>10803</td>\n",
       "      <td>10803</td>\n",
       "      <td>113774</td>\n",
       "      <td>4EQYur0tRZpHbQJxgCRy4Q</td>\n",
       "      <td>Michael W. Smith</td>\n",
       "      <td>Worship</td>\n",
       "      <td>More Love, More Power - Live</td>\n",
       "      <td>39</td>\n",
       "      <td>310293</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>142.075</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>love power life love power life worship heart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5898</th>\n",
       "      <td>10805</td>\n",
       "      <td>10805</td>\n",
       "      <td>113108</td>\n",
       "      <td>6CW9qtzZpHZ3o39BYlpU0x</td>\n",
       "      <td>Bethel Music;Bethany Wohrle</td>\n",
       "      <td>Living Hope</td>\n",
       "      <td>Living Hope</td>\n",
       "      <td>53</td>\n",
       "      <td>406346</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>143.957</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>great chasm lay high mountain climb desperatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>10807</td>\n",
       "      <td>10807</td>\n",
       "      <td>113056</td>\n",
       "      <td>2elEVvWjPZltkotzcCwKvM</td>\n",
       "      <td>Kari Jobe;Cody Carnes;Elevation Worship</td>\n",
       "      <td>The Blessing (Live)</td>\n",
       "      <td>The Blessing - Live</td>\n",
       "      <td>61</td>\n",
       "      <td>514665</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>140.015</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lord bless keep make face shine upon gracious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>10808</td>\n",
       "      <td>10808</td>\n",
       "      <td>113757</td>\n",
       "      <td>2q7NWcqIPqAr6bBF6Heqs7</td>\n",
       "      <td>Hillsong Kids</td>\n",
       "      <td>Can You Believe It!?</td>\n",
       "      <td>Who You Say I Am</td>\n",
       "      <td>36</td>\n",
       "      <td>239040</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>171.987</td>\n",
       "      <td>3</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>highest king welcome lost brought oh love oh l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5901 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  record_id  Unnamed: 0                track_id   \n",
       "0                1          1         740  1T7Tqsfkz0Ntbwta2hHebY  \\\n",
       "1                3          3         513  27hFQQS3cVUmIK3ser5bpu   \n",
       "2                4          4         136  2PIlBukQ6limukVR8Ubb5o   \n",
       "3                5          5         899  4uPvXmXGjYOOqhbRMmS9XU   \n",
       "4                9          9         549  2saK0E712wIB3Gf8QLuFYX   \n",
       "...            ...        ...         ...                     ...   \n",
       "5896         10802      10802      113500  2kDe0QRaCBKIh8QY64GDvK   \n",
       "5897         10803      10803      113774  4EQYur0tRZpHbQJxgCRy4Q   \n",
       "5898         10805      10805      113108  6CW9qtzZpHZ3o39BYlpU0x   \n",
       "5899         10807      10807      113056  2elEVvWjPZltkotzcCwKvM   \n",
       "5900         10808      10808      113757  2q7NWcqIPqAr6bBF6Heqs7   \n",
       "\n",
       "                                      artists                    album_name   \n",
       "0                                 Days N Daze               Rogue Taxidermy  \\\n",
       "1                            Colin & Caroline             More Than Gravity   \n",
       "2                             Gabrielle Aplin                  English Rain   \n",
       "3                                Grace Petrie                 Queer As Folk   \n",
       "4                                    Get Dead        Dancing with the Curse   \n",
       "...                                       ...                           ...   \n",
       "5896                Bethel Music;Jenn Johnson  We Will Not Be Shaken (Live)   \n",
       "5897                         Michael W. Smith                       Worship   \n",
       "5898              Bethel Music;Bethany Wohrle                   Living Hope   \n",
       "5899  Kari Jobe;Cody Carnes;Elevation Worship           The Blessing (Live)   \n",
       "5900                            Hillsong Kids          Can You Believe It!?   \n",
       "\n",
       "                                  track_name  popularity  duration_ms   \n",
       "0                           Fate of a Coward          28       175046  \\\n",
       "1                          More Than Gravity          34       266078   \n",
       "2               Please Don't Say You Love Me          59       181400   \n",
       "3                                 Northbound          26       270920   \n",
       "4                              Nickel Plated          29       136815   \n",
       "...                                      ...         ...          ...   \n",
       "5896  In Over My Head (Crash Over Me) - Live          49       298681   \n",
       "5897            More Love, More Power - Live          39       310293   \n",
       "5898                             Living Hope          53       406346   \n",
       "5899                     The Blessing - Live          61       514665   \n",
       "5900                        Who You Say I Am          36       239040   \n",
       "\n",
       "      explicit  ...  instrumentalness  liveness  valence    tempo   \n",
       "0        False  ...          0.000000    0.3510   0.9430  123.094  \\\n",
       "1        False  ...          0.000039    0.1060   0.2170  110.969   \n",
       "2        False  ...          0.000000    0.1080   0.3210   85.994   \n",
       "3        False  ...          0.000000    0.1410   0.5860  125.642   \n",
       "4         True  ...          0.000000    0.6540   0.4000  179.920   \n",
       "...        ...  ...               ...       ...      ...      ...   \n",
       "5896     False  ...          0.029400    0.0833   0.0896  141.800   \n",
       "5897     False  ...          0.000094    0.3440   0.1510  142.075   \n",
       "5898     False  ...          0.000000    0.5290   0.1850  143.957   \n",
       "5899     False  ...          0.000000    0.2220   0.1970  140.015   \n",
       "5900     False  ...          0.000000    0.0868   0.3240  171.987   \n",
       "\n",
       "      time_signature  track_genre  valence_bin  energy_bin  danceability_bin   \n",
       "0                  4     acoustic            2         1.0                 1  \\\n",
       "1                  4     acoustic            0         1.0                 1   \n",
       "2                  4     acoustic            0         1.0                 1   \n",
       "3                  4     acoustic            1         2.0                 1   \n",
       "4                  4     acoustic            1         2.0                 1   \n",
       "...              ...          ...          ...         ...               ...   \n",
       "5896               3  world-music            0         1.0                 1   \n",
       "5897               4  world-music            0         0.0                 0   \n",
       "5898               4  world-music            0         2.0                 1   \n",
       "5899               4  world-music            0         1.0                 1   \n",
       "5900               3  world-music            0         1.0                 1   \n",
       "\n",
       "                                                 lyrics  \n",
       "0     mind seeping darkness pulse growing weaker mom...  \n",
       "1     simple explanation things feel one word tell t...  \n",
       "2     summer comes winter fades not pressure not cha...  \n",
       "3     gone lonesome road goes forever espresso shot ...  \n",
       "4     nickel plated tooth briefcase hold breath poli...  \n",
       "...                                                 ...  \n",
       "5896  come place life full satisfied longing feel he...  \n",
       "5897  love power life love power life worship heart ...  \n",
       "5898  great chasm lay high mountain climb desperatio...  \n",
       "5899  lord bless keep make face shine upon gracious ...  \n",
       "5900  highest king welcome lost brought oh love oh l...  \n",
       "\n",
       "[5901 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5901"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyrics_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>record_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>valence_bin</th>\n",
       "      <th>energy_bin</th>\n",
       "      <th>danceability_bin</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>740</td>\n",
       "      <td>1T7Tqsfkz0Ntbwta2hHebY</td>\n",
       "      <td>Days N Daze</td>\n",
       "      <td>Rogue Taxidermy</td>\n",
       "      <td>Fate of a Coward</td>\n",
       "      <td>28</td>\n",
       "      <td>175046</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.9430</td>\n",
       "      <td>123.094</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>mind seeping darkness pulse growing weaker mom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>513</td>\n",
       "      <td>27hFQQS3cVUmIK3ser5bpu</td>\n",
       "      <td>Colin &amp; Caroline</td>\n",
       "      <td>More Than Gravity</td>\n",
       "      <td>More Than Gravity</td>\n",
       "      <td>34</td>\n",
       "      <td>266078</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>110.969</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>simple explanation things feel one word tell t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>2PIlBukQ6limukVR8Ubb5o</td>\n",
       "      <td>Gabrielle Aplin</td>\n",
       "      <td>English Rain</td>\n",
       "      <td>Please Don't Say You Love Me</td>\n",
       "      <td>59</td>\n",
       "      <td>181400</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>85.994</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>summer comes winter fades not pressure not cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>899</td>\n",
       "      <td>4uPvXmXGjYOOqhbRMmS9XU</td>\n",
       "      <td>Grace Petrie</td>\n",
       "      <td>Queer As Folk</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>26</td>\n",
       "      <td>270920</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>125.642</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>gone lonesome road goes forever espresso shot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>549</td>\n",
       "      <td>2saK0E712wIB3Gf8QLuFYX</td>\n",
       "      <td>Get Dead</td>\n",
       "      <td>Dancing with the Curse</td>\n",
       "      <td>Nickel Plated</td>\n",
       "      <td>29</td>\n",
       "      <td>136815</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6540</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>179.920</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>nickel plated tooth briefcase hold breath poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>10802</td>\n",
       "      <td>10802</td>\n",
       "      <td>113500</td>\n",
       "      <td>2kDe0QRaCBKIh8QY64GDvK</td>\n",
       "      <td>Bethel Music;Jenn Johnson</td>\n",
       "      <td>We Will Not Be Shaken (Live)</td>\n",
       "      <td>In Over My Head (Crash Over Me) - Live</td>\n",
       "      <td>49</td>\n",
       "      <td>298681</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>141.800</td>\n",
       "      <td>3</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>come place life full satisfied longing feel he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5897</th>\n",
       "      <td>10803</td>\n",
       "      <td>10803</td>\n",
       "      <td>113774</td>\n",
       "      <td>4EQYur0tRZpHbQJxgCRy4Q</td>\n",
       "      <td>Michael W. Smith</td>\n",
       "      <td>Worship</td>\n",
       "      <td>More Love, More Power - Live</td>\n",
       "      <td>39</td>\n",
       "      <td>310293</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>142.075</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>love power life love power life worship heart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5898</th>\n",
       "      <td>10805</td>\n",
       "      <td>10805</td>\n",
       "      <td>113108</td>\n",
       "      <td>6CW9qtzZpHZ3o39BYlpU0x</td>\n",
       "      <td>Bethel Music;Bethany Wohrle</td>\n",
       "      <td>Living Hope</td>\n",
       "      <td>Living Hope</td>\n",
       "      <td>53</td>\n",
       "      <td>406346</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>143.957</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>great chasm lay high mountain climb desperatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>10807</td>\n",
       "      <td>10807</td>\n",
       "      <td>113056</td>\n",
       "      <td>2elEVvWjPZltkotzcCwKvM</td>\n",
       "      <td>Kari Jobe;Cody Carnes;Elevation Worship</td>\n",
       "      <td>The Blessing (Live)</td>\n",
       "      <td>The Blessing - Live</td>\n",
       "      <td>61</td>\n",
       "      <td>514665</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>140.015</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lord bless keep make face shine upon gracious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>10808</td>\n",
       "      <td>10808</td>\n",
       "      <td>113757</td>\n",
       "      <td>2q7NWcqIPqAr6bBF6Heqs7</td>\n",
       "      <td>Hillsong Kids</td>\n",
       "      <td>Can You Believe It!?</td>\n",
       "      <td>Who You Say I Am</td>\n",
       "      <td>36</td>\n",
       "      <td>239040</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>171.987</td>\n",
       "      <td>3</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>highest king welcome lost brought oh love oh l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5901 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  record_id  Unnamed: 0                track_id   \n",
       "0                1          1         740  1T7Tqsfkz0Ntbwta2hHebY  \\\n",
       "1                3          3         513  27hFQQS3cVUmIK3ser5bpu   \n",
       "2                4          4         136  2PIlBukQ6limukVR8Ubb5o   \n",
       "3                5          5         899  4uPvXmXGjYOOqhbRMmS9XU   \n",
       "4                9          9         549  2saK0E712wIB3Gf8QLuFYX   \n",
       "...            ...        ...         ...                     ...   \n",
       "5896         10802      10802      113500  2kDe0QRaCBKIh8QY64GDvK   \n",
       "5897         10803      10803      113774  4EQYur0tRZpHbQJxgCRy4Q   \n",
       "5898         10805      10805      113108  6CW9qtzZpHZ3o39BYlpU0x   \n",
       "5899         10807      10807      113056  2elEVvWjPZltkotzcCwKvM   \n",
       "5900         10808      10808      113757  2q7NWcqIPqAr6bBF6Heqs7   \n",
       "\n",
       "                                      artists                    album_name   \n",
       "0                                 Days N Daze               Rogue Taxidermy  \\\n",
       "1                            Colin & Caroline             More Than Gravity   \n",
       "2                             Gabrielle Aplin                  English Rain   \n",
       "3                                Grace Petrie                 Queer As Folk   \n",
       "4                                    Get Dead        Dancing with the Curse   \n",
       "...                                       ...                           ...   \n",
       "5896                Bethel Music;Jenn Johnson  We Will Not Be Shaken (Live)   \n",
       "5897                         Michael W. Smith                       Worship   \n",
       "5898              Bethel Music;Bethany Wohrle                   Living Hope   \n",
       "5899  Kari Jobe;Cody Carnes;Elevation Worship           The Blessing (Live)   \n",
       "5900                            Hillsong Kids          Can You Believe It!?   \n",
       "\n",
       "                                  track_name  popularity  duration_ms   \n",
       "0                           Fate of a Coward          28       175046  \\\n",
       "1                          More Than Gravity          34       266078   \n",
       "2               Please Don't Say You Love Me          59       181400   \n",
       "3                                 Northbound          26       270920   \n",
       "4                              Nickel Plated          29       136815   \n",
       "...                                      ...         ...          ...   \n",
       "5896  In Over My Head (Crash Over Me) - Live          49       298681   \n",
       "5897            More Love, More Power - Live          39       310293   \n",
       "5898                             Living Hope          53       406346   \n",
       "5899                     The Blessing - Live          61       514665   \n",
       "5900                        Who You Say I Am          36       239040   \n",
       "\n",
       "      explicit  ...  instrumentalness  liveness  valence    tempo   \n",
       "0        False  ...          0.000000    0.3510   0.9430  123.094  \\\n",
       "1        False  ...          0.000039    0.1060   0.2170  110.969   \n",
       "2        False  ...          0.000000    0.1080   0.3210   85.994   \n",
       "3        False  ...          0.000000    0.1410   0.5860  125.642   \n",
       "4         True  ...          0.000000    0.6540   0.4000  179.920   \n",
       "...        ...  ...               ...       ...      ...      ...   \n",
       "5896     False  ...          0.029400    0.0833   0.0896  141.800   \n",
       "5897     False  ...          0.000094    0.3440   0.1510  142.075   \n",
       "5898     False  ...          0.000000    0.5290   0.1850  143.957   \n",
       "5899     False  ...          0.000000    0.2220   0.1970  140.015   \n",
       "5900     False  ...          0.000000    0.0868   0.3240  171.987   \n",
       "\n",
       "      time_signature  track_genre  valence_bin  energy_bin  danceability_bin   \n",
       "0                  4     acoustic            2         1.0                 1  \\\n",
       "1                  4     acoustic            0         1.0                 1   \n",
       "2                  4     acoustic            0         1.0                 1   \n",
       "3                  4     acoustic            1         2.0                 1   \n",
       "4                  4     acoustic            1         2.0                 1   \n",
       "...              ...          ...          ...         ...               ...   \n",
       "5896               3  world-music            0         1.0                 1   \n",
       "5897               4  world-music            0         0.0                 0   \n",
       "5898               4  world-music            0         2.0                 1   \n",
       "5899               4  world-music            0         1.0                 1   \n",
       "5900               3  world-music            0         1.0                 1   \n",
       "\n",
       "                                                 lyrics  \n",
       "0     mind seeping darkness pulse growing weaker mom...  \n",
       "1     simple explanation things feel one word tell t...  \n",
       "2     summer comes winter fades not pressure not cha...  \n",
       "3     gone lonesome road goes forever espresso shot ...  \n",
       "4     nickel plated tooth briefcase hold breath poli...  \n",
       "...                                                 ...  \n",
       "5896  come place life full satisfied longing feel he...  \n",
       "5897  love power life love power life worship heart ...  \n",
       "5898  great chasm lay high mountain climb desperatio...  \n",
       "5899  lord bless keep make face shine upon gracious ...  \n",
       "5900  highest king welcome lost brought oh love oh l...  \n",
       "\n",
       "[5901 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/np_utils.py:62: RuntimeWarning: invalid value encountered in cast\n",
      "  y = np.array(y, dtype=\"int\")\n"
     ]
    }
   ],
   "source": [
    "# 使用 Tokenizer 处理文本\n",
    "max_words = 5000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['lyrics'])\n",
    "sequences = tokenizer.texts_to_sequences(data['lyrics'])\n",
    "X_lyrics = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# 准备标签\n",
    "y_valence = to_categorical(data['valence_bin'].values)\n",
    "y_energy = to_categorical(data['energy_bin'].values)\n",
    "y_danceability = to_categorical(data['danceability_bin'].values)\n",
    "\n",
    "# 拆分数据集\n",
    "X_train_val, X_test, y_train_val_valence, y_test_valence, y_train_val_energy, y_test_energy, y_train_val_danceability, y_test_danceability = train_test_split(\n",
    "    X_lyrics, y_valence, y_energy, y_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train_valence, y_val_valence, y_train_energy, y_val_energy, y_train_danceability, y_val_danceability = train_test_split(\n",
    "    X_train_val, y_train_val_valence, y_train_val_energy, y_train_val_danceability, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 229,  582,  229, ...,  146,  119,   31],\n",
       "       [   1,    7,  903, ...,   11,  142,   31],\n",
       "       [ 729,    1,  342, ...,   87,  694,   31],\n",
       "       ...,\n",
       "       [  39,    3,   16, ...,   45,  150,   45],\n",
       "       [ 155,  208,  952, ...,   70,  613,   31],\n",
       "       [2505,   54,    7, ...,  299,  428,   31]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_dir/mood_detection5/tuner0.json\n",
      "{'input_dim': 7000, 'output_dim': 32, 'num_layers': 2, 'units_layer1': 320, 'dropout_layer1': 0.30000000000000004, 'units_final': 384, 'l2_regularization': 0.0, 'kernel_initializer': 'glorot_uniform', 'optimizer': 'adam', 'learning_rate': 0.001, 'units_layer2': 32, 'dropout_layer2': 0.0}\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.4744 - valence_output_loss: 1.2052 - energy_output_loss: 1.2697 - danceability_output_loss: 0.9995 - valence_output_accuracy: 0.6274 - energy_output_accuracy: 0.6749 - danceability_output_accuracy: 0.7341\n",
      "Test Loss: 3.4744436740875244, valence_output_loss: 1.2052104473114014, energy_output_loss: 1.2696882486343384, danceability_output_loss: 0.9995446801185608, Test Accuracy Valence: 0.6274343729019165, Test Accuracy Energy: 0.6748518347740173, Test Accuracy Danceability: 0.7341236472129822\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch, HyperParameters, Objective\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# 构建模型函数\n",
    "def build_model(hp):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=hp.Int('input_dim', min_value=1000, max_value=10000, step=1000),\n",
    "                  output_dim=hp.Int('output_dim', min_value=32, max_value=128, step=32),\n",
    "                  input_length=max_len)(inputs)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=5, step=1)\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            x = Dense(units=hp.Int(f'units_layer{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        else:\n",
    "            x = Dense(units=hp.Int(f'units_layer{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        x = Dropout(rate=hp.Float(f'dropout_layer{i+1}', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
    "\n",
    "    x = Dense(units=hp.Int('units_final', min_value=32, max_value=512, step=32),\n",
    "              activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(hp.Choice('l2_regularization', values=[0.0, 1e-4, 1e-3])),\n",
    "              kernel_initializer=hp.Choice('kernel_initializer', values=['glorot_uniform', 'he_normal']))(x)\n",
    "\n",
    "    \n",
    "    output_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(x)\n",
    "    output_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(x)\n",
    "    output_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[output_valence, output_energy, output_danceability])\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# 超参数调优\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=Objective('val_valence_output_accuracy', direction='max'),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='mood_detection5'\n",
    ")\n",
    "\n",
    "# 启动调优过程\n",
    "tuner.search(X_train, [y_train_valence, y_train_energy, y_train_danceability], \n",
    "             epochs=20, \n",
    "             validation_data=(X_val, [y_val_valence, y_val_energy, y_val_danceability]), \n",
    "             callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# 评估模型\n",
    "\n",
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 3.4744 - valence_output_loss: 1.2052 - energy_output_loss: 1.2697 - danceability_output_loss: 0.9995 - valence_output_accuracy: 0.6274 - energy_output_accuracy: 0.6749 - danceability_output_accuracy: 0.7341\n",
      "[3.4744436740875244, 1.2052104473114014, 1.2696882486343384, 0.9995446801185608, 0.6274343729019165, 0.6748518347740173, 0.7341236472129822]\n"
     ]
    }
   ],
   "source": [
    "metrics = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "#print(f'Test Loss: {loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 12s]\n",
      "val_valence_output_accuracy: 0.6536017060279846\n",
      "\n",
      "Best val_valence_output_accuracy So Far: 0.6546609997749329\n",
      "Total elapsed time: 00h 02m 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_output_dim': 32, 'filters': 96, 'kernel_size': 7, 'pool_size': 2, 'num_layers': 1, 'dense_units_1': 416, 'dropout_1': 0.4, 'optimizer': 'rmsprop', 'learning_rate': 0.001}\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3.3224 - valence_output_loss: 1.1877 - energy_output_loss: 1.2021 - danceability_output_loss: 0.9325 - valence_output_accuracy: 0.6613 - energy_output_accuracy: 0.6520 - danceability_output_accuracy: 0.7722\n",
      "Test Loss: 3.3223869800567627, valence_output_loss: 1.187723159790039, energy_output_loss: 1.2021470069885254, danceability_output_loss: 0.9325172305107117, Test Accuracy Valence: 0.6613039970397949, Test Accuracy Energy: 0.6519898176193237, Test Accuracy Danceability: 0.7722269296646118\n"
     ]
    }
   ],
   "source": [
    "# 构建 CNN 模型函数\n",
    "def build_cnn_model(hp):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=max_words, output_dim=hp.Int('embedding_output_dim', min_value=32, max_value=128, step=32), input_length=max_len)(inputs)\n",
    "    x = tf.keras.layers.Conv1D(filters=hp.Int('filters', min_value=32, max_value=128, step=32), kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=2), activation='relu')(x)\n",
    "    x = tf.keras.layers.AveragePooling1D(pool_size=hp.Int('pool_size', min_value=2, max_value=5, step=1))(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
    "    for i in range(num_layers):\n",
    "        x = Dense(units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        x = Dropout(rate=hp.Float(f'dropout_{i+1}', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    output_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(x)\n",
    "    output_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(x)\n",
    "    output_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[output_valence, output_energy, output_danceability])\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# 超参数调优\n",
    "tuner = RandomSearch(\n",
    "    build_cnn_model,\n",
    "    objective=Objective('val_valence_output_accuracy', direction='max'),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='cnn_mood_detection2'\n",
    ")\n",
    "\n",
    "# 启动调优过程\n",
    "tuner.search(X_train, [y_train_valence, y_train_energy, y_train_danceability], \n",
    "             epochs=20, \n",
    "             validation_data=(X_val, [y_val_valence, y_val_energy, y_val_danceability]), \n",
    "             callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# 评估模型\n",
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "def tokenize(dataframe, tokenizer, max_len=128):\n",
    "    tokenized_dict = {}\n",
    "    for data_point in dataframe.iterrows():\n",
    "        sent = data_point[1]['lyrics']\n",
    "        id = data_point[1]['record_id']\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text=sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True\n",
    "        )\n",
    "        tokenized_dict[data_point[0]] = {\"id\":id, \"input_ids\":encoded['input_ids'], \"attention_mask\": encoded['attention_mask']}\n",
    "    return tokenized_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_len = 128\n",
    "\n",
    "tokenized_dict = tokenize(data, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert, X_test_bert = train_test_split(tokenized_dict, random_state=42, test_size=0.2)\n",
    "X_train_bert_part, X_val_bert = train_test_split(X_train_bert, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(key_name, dict):\n",
    "    return [i[key_name] for i in dict]\n",
    "\n",
    "X_train_input_ids, X_val_input_ids, X_test_input_ids = get_list(\"input_ids\", X_train_bert), get_list(\"input_ids\", X_val_bert), get_list(\"input_ids\", X_test_bert)\n",
    "X_train_attention_masks, X_val_attention_masks, X_test_attention_masks = get_list(\"attention_mask\", X_train_bert), get_list(\"attention_mask\", X_val_bert), get_list(\"attention_mask\", X_test_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\\'(<class \\\\\\'list\\\\\\'> containing values of types {\"<class \\\\\\'int\\\\\\'>\"})\\'})'}), (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m build_bert_model()\n\u001b[1;32m     29\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_attention_masks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train_valence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_energy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_danceability\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_attention_masks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_val_valence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_energy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_danceability\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 评估模型\u001b[39;00m\n\u001b[1;32m     41\u001b[0m loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m     42\u001b[0m     [X_test_input_ids, X_test_attention_masks], \n\u001b[1;32m     43\u001b[0m     [y_test_valence, y_test_energy, y_test_danceability]\n\u001b[1;32m     44\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1102\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1104\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m     )\n\u001b[1;32m   1110\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1111\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1115\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\\'(<class \\\\\\'list\\\\\\'> containing values of types {\"<class \\\\\\'int\\\\\\'>\"})\\'})'}), (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"})"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 构建BERT模型\n",
    "def build_bert_model():\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]\n",
    "    cls_token = bert_output[:, 0, :]\n",
    "    \n",
    "    dense_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(cls_token)\n",
    "    dense_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(cls_token)\n",
    "    dense_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[dense_valence, dense_energy, dense_danceability])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=2e-5)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# 构建并训练模型\n",
    "model = build_bert_model()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_input_ids, X_train_attention_masks],\n",
    "    [y_train_valence, y_train_energy, y_train_danceability],\n",
    "    validation_data=([X_val_input_ids, X_val_attention_masks], [y_val_valence, y_val_energy, y_val_danceability]),\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = model.evaluate(\n",
    "    [X_test_input_ids, X_test_attention_masks], \n",
    "    [y_test_valence, y_test_energy, y_test_danceability]\n",
    ")\n",
    "\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}')\n",
    "print(f'Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
