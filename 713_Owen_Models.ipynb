{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras_tuner import RandomSearch, HyperParameters, Objective\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, Callback\n",
    "from transformers import BertTokenizer, TFBertModel, get_linear_schedule_with_warmup, WarmUp, AdamW, RobertaTokenizer, TFRobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解压 cleaned_lyrics.zip 文件\n",
    "with zipfile.ZipFile('sampled.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('sampled')\n",
    "\n",
    "# 获取所有歌词文件的路径\n",
    "lyrics_files = {os.path.splitext(f)[0]: os.path.join('sampled', f) for f in os.listdir('sampled')}\n",
    "\n",
    "# 读取 filtered_dataset.csv 文件\n",
    "data = pd.read_csv('sampled_dataset.csv')\n",
    "\n",
    "def read_lyrics(record_id):\n",
    "    file_path = lyrics_files.get(str(record_id))\n",
    "    if file_path and os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    return ''\n",
    "\n",
    "# 读取歌词并添加到数据框中\n",
    "data['lyrics'] = data['record_id'].apply(read_lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>record_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>valence_bin</th>\n",
       "      <th>energy_bin</th>\n",
       "      <th>danceability_bin</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1458</td>\n",
       "      <td>2834</td>\n",
       "      <td>2834</td>\n",
       "      <td>20097</td>\n",
       "      <td>4b98LXC0QUWGBteJ5uwVQY</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Summer Music Festival Hits</td>\n",
       "      <td>Boss Bitch</td>\n",
       "      <td>0</td>\n",
       "      <td>134239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.575</td>\n",
       "      <td>125.993</td>\n",
       "      <td>4</td>\n",
       "      <td>dance</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>mmm not tryna ah not tryna not tryna yeah not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1557</td>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "      <td>22816</td>\n",
       "      <td>58Z83tSbShyHxCwqTCE8M6</td>\n",
       "      <td>Goatwhore</td>\n",
       "      <td>Vengeful Ascension</td>\n",
       "      <td>Under the Flesh, Into the Soul</td>\n",
       "      <td>21</td>\n",
       "      <td>273266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.347</td>\n",
       "      <td>170.015</td>\n",
       "      <td>4</td>\n",
       "      <td>death-metal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>world grave apathetic cold selfish prison cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>3220</td>\n",
       "      <td>0AOmbw8AwDnwXhHC3OhdVB</td>\n",
       "      <td>Thousand Foot Krutch</td>\n",
       "      <td>The End Is Where We Begin</td>\n",
       "      <td>Courtesy Call</td>\n",
       "      <td>72</td>\n",
       "      <td>236898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.445</td>\n",
       "      <td>164.079</td>\n",
       "      <td>4</td>\n",
       "      <td>alternative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hey comes danger club get started man not gonn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>989</td>\n",
       "      <td>2054</td>\n",
       "      <td>2054</td>\n",
       "      <td>14581</td>\n",
       "      <td>5Jaj6nLjHCizmcPddJLO3k</td>\n",
       "      <td>Blippi</td>\n",
       "      <td>Blippi Tunes, Vol. 2: Machines (Music for Todd...</td>\n",
       "      <td>The Train Song</td>\n",
       "      <td>53</td>\n",
       "      <td>207428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.662</td>\n",
       "      <td>139.895</td>\n",
       "      <td>4</td>\n",
       "      <td>children</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>choo choo comes train choo choo comes train ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>383</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>3717</td>\n",
       "      <td>2oaK4JLVnmRGIO9ytBE1bt</td>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>The Getaway</td>\n",
       "      <td>Dark Necessities</td>\n",
       "      <td>74</td>\n",
       "      <td>302000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.197</td>\n",
       "      <td>91.959</td>\n",
       "      <td>4</td>\n",
       "      <td>alternative</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>comin light day got many moons deep play keep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>658</td>\n",
       "      <td>1229</td>\n",
       "      <td>1229</td>\n",
       "      <td>8662</td>\n",
       "      <td>3hSy2AUoElgIk6fjhYnRH3</td>\n",
       "      <td>Elvin Bishop</td>\n",
       "      <td>Sure Feels Good: The Best Of Elvin Bishop</td>\n",
       "      <td>Fooled Around And Fell In Love</td>\n",
       "      <td>57</td>\n",
       "      <td>276933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.610</td>\n",
       "      <td>113.463</td>\n",
       "      <td>3</td>\n",
       "      <td>blues</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>million girls love em leave em alone not care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>5818</td>\n",
       "      <td>10682</td>\n",
       "      <td>10682</td>\n",
       "      <td>113479</td>\n",
       "      <td>5ELZpvTDGorz9BIE9zaBoZ</td>\n",
       "      <td>Tenth Avenue North</td>\n",
       "      <td>Followers</td>\n",
       "      <td>I Have This Hope</td>\n",
       "      <td>52</td>\n",
       "      <td>204800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.110</td>\n",
       "      <td>108.009</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>walk great unknown questions come questions go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>265</td>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "      <td>2185</td>\n",
       "      <td>3mJV4kByjmgU3ubU7JPp9W</td>\n",
       "      <td>Marilyn Manson</td>\n",
       "      <td>Halloween 2022</td>\n",
       "      <td>You And Me And The Devil Makes 3</td>\n",
       "      <td>0</td>\n",
       "      <td>264266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.399</td>\n",
       "      <td>128.021</td>\n",
       "      <td>4</td>\n",
       "      <td>alt-rock</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>like rolling stone hill hades want lie gonna l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>5031</td>\n",
       "      <td>9325</td>\n",
       "      <td>9325</td>\n",
       "      <td>94717</td>\n",
       "      <td>5xUpsNCW71S58c8TycsqNa</td>\n",
       "      <td>Ollie</td>\n",
       "      <td>Sunsets &amp; Goodbyes</td>\n",
       "      <td>what if</td>\n",
       "      <td>39</td>\n",
       "      <td>173615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.283</td>\n",
       "      <td>146.006</td>\n",
       "      <td>4</td>\n",
       "      <td>sad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yeah call one day everything yeah call next no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>5723</td>\n",
       "      <td>10541</td>\n",
       "      <td>10541</td>\n",
       "      <td>107316</td>\n",
       "      <td>7skyR8nK3vnDikYFBoUVw6</td>\n",
       "      <td>Laura Branigan</td>\n",
       "      <td>Self Control (Expanded)</td>\n",
       "      <td>Self Control - Extended Version</td>\n",
       "      <td>52</td>\n",
       "      <td>304893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.803</td>\n",
       "      <td>106.378</td>\n",
       "      <td>4</td>\n",
       "      <td>synth-pop</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>oh night world city light painted girl day not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.2  Unnamed: 0.1  record_id  Unnamed: 0   \n",
       "0            1458          2834       2834       20097  \\\n",
       "1            1557          2967       2967       22816   \n",
       "2             425           616        616        3220   \n",
       "3             989          2054       2054       14581   \n",
       "4             383           562        562        3717   \n",
       "..            ...           ...        ...         ...   \n",
       "595           658          1229       1229        8662   \n",
       "596          5818         10682      10682      113479   \n",
       "597           265           426        426        2185   \n",
       "598          5031          9325       9325       94717   \n",
       "599          5723         10541      10541      107316   \n",
       "\n",
       "                   track_id                artists   \n",
       "0    4b98LXC0QUWGBteJ5uwVQY               Doja Cat  \\\n",
       "1    58Z83tSbShyHxCwqTCE8M6              Goatwhore   \n",
       "2    0AOmbw8AwDnwXhHC3OhdVB   Thousand Foot Krutch   \n",
       "3    5Jaj6nLjHCizmcPddJLO3k                 Blippi   \n",
       "4    2oaK4JLVnmRGIO9ytBE1bt  Red Hot Chili Peppers   \n",
       "..                      ...                    ...   \n",
       "595  3hSy2AUoElgIk6fjhYnRH3           Elvin Bishop   \n",
       "596  5ELZpvTDGorz9BIE9zaBoZ     Tenth Avenue North   \n",
       "597  3mJV4kByjmgU3ubU7JPp9W         Marilyn Manson   \n",
       "598  5xUpsNCW71S58c8TycsqNa                  Ollie   \n",
       "599  7skyR8nK3vnDikYFBoUVw6         Laura Branigan   \n",
       "\n",
       "                                            album_name   \n",
       "0                           Summer Music Festival Hits  \\\n",
       "1                                   Vengeful Ascension   \n",
       "2                            The End Is Where We Begin   \n",
       "3    Blippi Tunes, Vol. 2: Machines (Music for Todd...   \n",
       "4                                          The Getaway   \n",
       "..                                                 ...   \n",
       "595          Sure Feels Good: The Best Of Elvin Bishop   \n",
       "596                                          Followers   \n",
       "597                                     Halloween 2022   \n",
       "598                                 Sunsets & Goodbyes   \n",
       "599                            Self Control (Expanded)   \n",
       "\n",
       "                           track_name  popularity  duration_ms  ...   \n",
       "0                          Boss Bitch           0       134239  ...  \\\n",
       "1      Under the Flesh, Into the Soul          21       273266  ...   \n",
       "2                       Courtesy Call          72       236898  ...   \n",
       "3                      The Train Song          53       207428  ...   \n",
       "4                    Dark Necessities          74       302000  ...   \n",
       "..                                ...         ...          ...  ...   \n",
       "595    Fooled Around And Fell In Love          57       276933  ...   \n",
       "596                  I Have This Hope          52       204800  ...   \n",
       "597  You And Me And The Devil Makes 3           0       264266  ...   \n",
       "598                           what if          39       173615  ...   \n",
       "599   Self Control - Extended Version          52       304893  ...   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  time_signature   \n",
       "0            0.000000    0.2030    0.575  125.993               4  \\\n",
       "1            0.110000    0.1070    0.347  170.015               4   \n",
       "2            0.000000    0.0822    0.445  164.079               4   \n",
       "3            0.000019    0.3250    0.662  139.895               4   \n",
       "4            0.019900    0.1100    0.197   91.959               4   \n",
       "..                ...       ...      ...      ...             ...   \n",
       "595          0.080500    0.0953    0.610  113.463               3   \n",
       "596          0.000000    0.1890    0.110  108.009               4   \n",
       "597          0.834000    0.2030    0.399  128.021               4   \n",
       "598          0.000627    0.0723    0.283  146.006               4   \n",
       "599          0.009970    0.1880    0.803  106.378               4   \n",
       "\n",
       "     track_genre  valence_bin  energy_bin  danceability_bin   \n",
       "0          dance            1           2                 2  \\\n",
       "1    death-metal            1           2                 0   \n",
       "2    alternative            1           1                 1   \n",
       "3       children            2           1                 2   \n",
       "4    alternative            0           2                 2   \n",
       "..           ...          ...         ...               ...   \n",
       "595        blues            1           1                 1   \n",
       "596  world-music            0           1                 1   \n",
       "597     alt-rock            1           2                 1   \n",
       "598          sad            0           0                 2   \n",
       "599    synth-pop            2           2                 2   \n",
       "\n",
       "                                                lyrics  \n",
       "0    mmm not tryna ah not tryna not tryna yeah not ...  \n",
       "1    world grave apathetic cold selfish prison cove...  \n",
       "2    hey comes danger club get started man not gonn...  \n",
       "3    choo choo comes train choo choo comes train ro...  \n",
       "4    comin light day got many moons deep play keep ...  \n",
       "..                                                 ...  \n",
       "595  million girls love em leave em alone not care ...  \n",
       "596  walk great unknown questions come questions go...  \n",
       "597  like rolling stone hill hades want lie gonna l...  \n",
       "598  yeah call one day everything yeah call next no...  \n",
       "599  oh night world city light painted girl day not...  \n",
       "\n",
       "[600 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyrics_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>record_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>valence_bin</th>\n",
       "      <th>energy_bin</th>\n",
       "      <th>danceability_bin</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1458</td>\n",
       "      <td>2834</td>\n",
       "      <td>2834</td>\n",
       "      <td>20097</td>\n",
       "      <td>4b98LXC0QUWGBteJ5uwVQY</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Summer Music Festival Hits</td>\n",
       "      <td>Boss Bitch</td>\n",
       "      <td>0</td>\n",
       "      <td>134239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.575</td>\n",
       "      <td>125.993</td>\n",
       "      <td>4</td>\n",
       "      <td>dance</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>mmm not tryna ah not tryna not tryna yeah not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1557</td>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "      <td>22816</td>\n",
       "      <td>58Z83tSbShyHxCwqTCE8M6</td>\n",
       "      <td>Goatwhore</td>\n",
       "      <td>Vengeful Ascension</td>\n",
       "      <td>Under the Flesh, Into the Soul</td>\n",
       "      <td>21</td>\n",
       "      <td>273266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.347</td>\n",
       "      <td>170.015</td>\n",
       "      <td>4</td>\n",
       "      <td>death-metal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>world grave apathetic cold selfish prison cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>3220</td>\n",
       "      <td>0AOmbw8AwDnwXhHC3OhdVB</td>\n",
       "      <td>Thousand Foot Krutch</td>\n",
       "      <td>The End Is Where We Begin</td>\n",
       "      <td>Courtesy Call</td>\n",
       "      <td>72</td>\n",
       "      <td>236898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.445</td>\n",
       "      <td>164.079</td>\n",
       "      <td>4</td>\n",
       "      <td>alternative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hey comes danger club get started man not gonn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>989</td>\n",
       "      <td>2054</td>\n",
       "      <td>2054</td>\n",
       "      <td>14581</td>\n",
       "      <td>5Jaj6nLjHCizmcPddJLO3k</td>\n",
       "      <td>Blippi</td>\n",
       "      <td>Blippi Tunes, Vol. 2: Machines (Music for Todd...</td>\n",
       "      <td>The Train Song</td>\n",
       "      <td>53</td>\n",
       "      <td>207428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.662</td>\n",
       "      <td>139.895</td>\n",
       "      <td>4</td>\n",
       "      <td>children</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>choo choo comes train choo choo comes train ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>383</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>3717</td>\n",
       "      <td>2oaK4JLVnmRGIO9ytBE1bt</td>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>The Getaway</td>\n",
       "      <td>Dark Necessities</td>\n",
       "      <td>74</td>\n",
       "      <td>302000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.197</td>\n",
       "      <td>91.959</td>\n",
       "      <td>4</td>\n",
       "      <td>alternative</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>comin light day got many moons deep play keep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>658</td>\n",
       "      <td>1229</td>\n",
       "      <td>1229</td>\n",
       "      <td>8662</td>\n",
       "      <td>3hSy2AUoElgIk6fjhYnRH3</td>\n",
       "      <td>Elvin Bishop</td>\n",
       "      <td>Sure Feels Good: The Best Of Elvin Bishop</td>\n",
       "      <td>Fooled Around And Fell In Love</td>\n",
       "      <td>57</td>\n",
       "      <td>276933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.610</td>\n",
       "      <td>113.463</td>\n",
       "      <td>3</td>\n",
       "      <td>blues</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>million girls love em leave em alone not care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>5818</td>\n",
       "      <td>10682</td>\n",
       "      <td>10682</td>\n",
       "      <td>113479</td>\n",
       "      <td>5ELZpvTDGorz9BIE9zaBoZ</td>\n",
       "      <td>Tenth Avenue North</td>\n",
       "      <td>Followers</td>\n",
       "      <td>I Have This Hope</td>\n",
       "      <td>52</td>\n",
       "      <td>204800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.110</td>\n",
       "      <td>108.009</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>walk great unknown questions come questions go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>265</td>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "      <td>2185</td>\n",
       "      <td>3mJV4kByjmgU3ubU7JPp9W</td>\n",
       "      <td>Marilyn Manson</td>\n",
       "      <td>Halloween 2022</td>\n",
       "      <td>You And Me And The Devil Makes 3</td>\n",
       "      <td>0</td>\n",
       "      <td>264266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.399</td>\n",
       "      <td>128.021</td>\n",
       "      <td>4</td>\n",
       "      <td>alt-rock</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>like rolling stone hill hades want lie gonna l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>5031</td>\n",
       "      <td>9325</td>\n",
       "      <td>9325</td>\n",
       "      <td>94717</td>\n",
       "      <td>5xUpsNCW71S58c8TycsqNa</td>\n",
       "      <td>Ollie</td>\n",
       "      <td>Sunsets &amp; Goodbyes</td>\n",
       "      <td>what if</td>\n",
       "      <td>39</td>\n",
       "      <td>173615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.283</td>\n",
       "      <td>146.006</td>\n",
       "      <td>4</td>\n",
       "      <td>sad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yeah call one day everything yeah call next no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>5723</td>\n",
       "      <td>10541</td>\n",
       "      <td>10541</td>\n",
       "      <td>107316</td>\n",
       "      <td>7skyR8nK3vnDikYFBoUVw6</td>\n",
       "      <td>Laura Branigan</td>\n",
       "      <td>Self Control (Expanded)</td>\n",
       "      <td>Self Control - Extended Version</td>\n",
       "      <td>52</td>\n",
       "      <td>304893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.803</td>\n",
       "      <td>106.378</td>\n",
       "      <td>4</td>\n",
       "      <td>synth-pop</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>oh night world city light painted girl day not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.2  Unnamed: 0.1  record_id  Unnamed: 0   \n",
       "0            1458          2834       2834       20097  \\\n",
       "1            1557          2967       2967       22816   \n",
       "2             425           616        616        3220   \n",
       "3             989          2054       2054       14581   \n",
       "4             383           562        562        3717   \n",
       "..            ...           ...        ...         ...   \n",
       "595           658          1229       1229        8662   \n",
       "596          5818         10682      10682      113479   \n",
       "597           265           426        426        2185   \n",
       "598          5031          9325       9325       94717   \n",
       "599          5723         10541      10541      107316   \n",
       "\n",
       "                   track_id                artists   \n",
       "0    4b98LXC0QUWGBteJ5uwVQY               Doja Cat  \\\n",
       "1    58Z83tSbShyHxCwqTCE8M6              Goatwhore   \n",
       "2    0AOmbw8AwDnwXhHC3OhdVB   Thousand Foot Krutch   \n",
       "3    5Jaj6nLjHCizmcPddJLO3k                 Blippi   \n",
       "4    2oaK4JLVnmRGIO9ytBE1bt  Red Hot Chili Peppers   \n",
       "..                      ...                    ...   \n",
       "595  3hSy2AUoElgIk6fjhYnRH3           Elvin Bishop   \n",
       "596  5ELZpvTDGorz9BIE9zaBoZ     Tenth Avenue North   \n",
       "597  3mJV4kByjmgU3ubU7JPp9W         Marilyn Manson   \n",
       "598  5xUpsNCW71S58c8TycsqNa                  Ollie   \n",
       "599  7skyR8nK3vnDikYFBoUVw6         Laura Branigan   \n",
       "\n",
       "                                            album_name   \n",
       "0                           Summer Music Festival Hits  \\\n",
       "1                                   Vengeful Ascension   \n",
       "2                            The End Is Where We Begin   \n",
       "3    Blippi Tunes, Vol. 2: Machines (Music for Todd...   \n",
       "4                                          The Getaway   \n",
       "..                                                 ...   \n",
       "595          Sure Feels Good: The Best Of Elvin Bishop   \n",
       "596                                          Followers   \n",
       "597                                     Halloween 2022   \n",
       "598                                 Sunsets & Goodbyes   \n",
       "599                            Self Control (Expanded)   \n",
       "\n",
       "                           track_name  popularity  duration_ms  ...   \n",
       "0                          Boss Bitch           0       134239  ...  \\\n",
       "1      Under the Flesh, Into the Soul          21       273266  ...   \n",
       "2                       Courtesy Call          72       236898  ...   \n",
       "3                      The Train Song          53       207428  ...   \n",
       "4                    Dark Necessities          74       302000  ...   \n",
       "..                                ...         ...          ...  ...   \n",
       "595    Fooled Around And Fell In Love          57       276933  ...   \n",
       "596                  I Have This Hope          52       204800  ...   \n",
       "597  You And Me And The Devil Makes 3           0       264266  ...   \n",
       "598                           what if          39       173615  ...   \n",
       "599   Self Control - Extended Version          52       304893  ...   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  time_signature   \n",
       "0            0.000000    0.2030    0.575  125.993               4  \\\n",
       "1            0.110000    0.1070    0.347  170.015               4   \n",
       "2            0.000000    0.0822    0.445  164.079               4   \n",
       "3            0.000019    0.3250    0.662  139.895               4   \n",
       "4            0.019900    0.1100    0.197   91.959               4   \n",
       "..                ...       ...      ...      ...             ...   \n",
       "595          0.080500    0.0953    0.610  113.463               3   \n",
       "596          0.000000    0.1890    0.110  108.009               4   \n",
       "597          0.834000    0.2030    0.399  128.021               4   \n",
       "598          0.000627    0.0723    0.283  146.006               4   \n",
       "599          0.009970    0.1880    0.803  106.378               4   \n",
       "\n",
       "     track_genre  valence_bin  energy_bin  danceability_bin   \n",
       "0          dance            1           2                 2  \\\n",
       "1    death-metal            1           2                 0   \n",
       "2    alternative            1           1                 1   \n",
       "3       children            2           1                 2   \n",
       "4    alternative            0           2                 2   \n",
       "..           ...          ...         ...               ...   \n",
       "595        blues            1           1                 1   \n",
       "596  world-music            0           1                 1   \n",
       "597     alt-rock            1           2                 1   \n",
       "598          sad            0           0                 2   \n",
       "599    synth-pop            2           2                 2   \n",
       "\n",
       "                                                lyrics  \n",
       "0    mmm not tryna ah not tryna not tryna yeah not ...  \n",
       "1    world grave apathetic cold selfish prison cove...  \n",
       "2    hey comes danger club get started man not gonn...  \n",
       "3    choo choo comes train choo choo comes train ro...  \n",
       "4    comin light day got many moons deep play keep ...  \n",
       "..                                                 ...  \n",
       "595  million girls love em leave em alone not care ...  \n",
       "596  walk great unknown questions come questions go...  \n",
       "597  like rolling stone hill hades want lie gonna l...  \n",
       "598  yeah call one day everything yeah call next no...  \n",
       "599  oh night world city light painted girl day not...  \n",
       "\n",
       "[600 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Tokenizer 处理文本\n",
    "max_words = 5000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['lyrics'])\n",
    "sequences = tokenizer.texts_to_sequences(data['lyrics'])\n",
    "X_lyrics = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# 准备标签\n",
    "y_valence = to_categorical(data['valence_bin'].values)\n",
    "y_energy = to_categorical(data['energy_bin'].values)\n",
    "y_danceability = to_categorical(data['danceability_bin'].values)\n",
    "\n",
    "# 拆分数据集\n",
    "X_train_val, X_test, y_train_val_valence, y_test_valence, y_train_val_energy, y_test_energy, y_train_val_danceability, y_test_danceability = train_test_split(\n",
    "    X_lyrics, y_valence, y_energy, y_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train_valence, y_val_valence, y_train_energy, y_val_energy, y_train_danceability, y_val_danceability = train_test_split(\n",
    "    X_train_val, y_train_val_valence, y_train_val_energy, y_train_val_danceability, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9,   80,   77, ...,  718, 3619,   32],\n",
       "       [  28,  344,  780, ...,  344,  780,   32],\n",
       "       [  77,  609,  198, ...,  609,  198,   32],\n",
       "       ...,\n",
       "       [   1,    1,  433, ...,   28,   44,   32],\n",
       "       [ 653, 1380,  591, ...,    4,  203,   32],\n",
       "       [  58,  135,   13, ..., 1744,  313,   32]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 03s]\n",
      "val_valence_output_accuracy: 0.5\n",
      "\n",
      "Best val_valence_output_accuracy So Far: 0.5\n",
      "Total elapsed time: 00h 00m 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_dim': 6000, 'output_dim': 32, 'num_layers': 2, 'units_layer1': 320, 'dropout_layer1': 0.1, 'units_final': 320, 'l2_regularization': 0.0, 'kernel_initializer': 'he_normal', 'optimizer': 'adam', 'learning_rate': 1e-05, 'units_layer2': 160, 'dropout_layer2': 0.2, 'units_layer3': 256, 'dropout_layer3': 0.4, 'units_layer4': 288, 'dropout_layer4': 0.0}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2663 - valence_output_loss: 1.0943 - energy_output_loss: 1.0905 - danceability_output_loss: 1.0815 - valence_output_accuracy: 0.4083 - energy_output_accuracy: 0.4500 - danceability_output_accuracy: 0.4167\n",
      "Test Loss: 3.2663047313690186, valence_output_loss: 1.094298005104065, energy_output_loss: 1.0904593467712402, danceability_output_loss: 1.081547498703003, Test Accuracy Valence: 0.40833333134651184, Test Accuracy Energy: 0.44999998807907104, Test Accuracy Danceability: 0.4166666567325592\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch, HyperParameters, Objective\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# 构建模型函数\n",
    "def build_model(hp):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=hp.Int('input_dim', min_value=1000, max_value=10000, step=1000),\n",
    "                  output_dim=hp.Int('output_dim', min_value=32, max_value=128, step=32),\n",
    "                  input_length=max_len)(inputs)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=5, step=1)\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            x = Dense(units=hp.Int(f'units_layer{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        else:\n",
    "            x = Dense(units=hp.Int(f'units_layer{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        x = Dropout(rate=hp.Float(f'dropout_layer{i+1}', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
    "\n",
    "    x = Dense(units=hp.Int('units_final', min_value=32, max_value=512, step=32),\n",
    "              activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(hp.Choice('l2_regularization', values=[0.0, 1e-4, 1e-3])),\n",
    "              kernel_initializer=hp.Choice('kernel_initializer', values=['glorot_uniform', 'he_normal']))(x)\n",
    "\n",
    "    \n",
    "    output_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(x)\n",
    "    output_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(x)\n",
    "    output_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[output_valence, output_energy, output_danceability])\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# 超参数调优\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=Objective('val_valence_output_accuracy', direction='max'),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='dnn_mood_detection_600'\n",
    ")\n",
    "\n",
    "# 启动调优过程\n",
    "tuner.search(X_train, [y_train_valence, y_train_energy, y_train_danceability], \n",
    "             epochs=20, \n",
    "             validation_data=(X_val, [y_val_valence, y_val_energy, y_val_danceability]), \n",
    "             callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# 评估模型\n",
    "\n",
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2663 - valence_output_loss: 1.0943 - energy_output_loss: 1.0905 - danceability_output_loss: 1.0815 - valence_output_accuracy: 0.4083 - energy_output_accuracy: 0.4500 - danceability_output_accuracy: 0.4167\n",
      "[3.2663047313690186, 1.094298005104065, 1.0904593467712402, 1.081547498703003, 0.40833333134651184, 0.44999998807907104, 0.4166666567325592]\n"
     ]
    }
   ],
   "source": [
    "metrics = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "#print(f'Test Loss: {loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 02s]\n",
      "val_valence_output_accuracy: 0.5\n",
      "\n",
      "Best val_valence_output_accuracy So Far: 0.5625\n",
      "Total elapsed time: 00h 00m 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_output_dim': 128, 'filters': 96, 'kernel_size': 7, 'pool_size': 2, 'num_layers': 1, 'dense_units_1': 192, 'dropout_1': 0.1, 'optimizer': 'adam', 'learning_rate': 0.001, 'dense_units_2': 192, 'dropout_2': 0.0, 'dense_units_3': 320, 'dropout_3': 0.30000000000000004}\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.1327 - valence_output_loss: 1.0610 - energy_output_loss: 1.0361 - danceability_output_loss: 1.0356 - valence_output_accuracy: 0.4167 - energy_output_accuracy: 0.4583 - danceability_output_accuracy: 0.4583\n",
      "Test Loss: 3.132678270339966, valence_output_loss: 1.0609853267669678, energy_output_loss: 1.0360546112060547, danceability_output_loss: 1.0356380939483643, Test Accuracy Valence: 0.4166666567325592, Test Accuracy Energy: 0.4583333432674408, Test Accuracy Danceability: 0.4583333432674408\n"
     ]
    }
   ],
   "source": [
    "# 构建 CNN 模型函数\n",
    "def build_cnn_model(hp):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=max_words, output_dim=hp.Int('embedding_output_dim', min_value=32, max_value=128, step=32), input_length=max_len)(inputs)\n",
    "    x = tf.keras.layers.Conv1D(filters=hp.Int('filters', min_value=32, max_value=128, step=32), kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=2), activation='relu')(x)\n",
    "    x = tf.keras.layers.AveragePooling1D(pool_size=hp.Int('pool_size', min_value=2, max_value=5, step=1))(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
    "    for i in range(num_layers):\n",
    "        x = Dense(units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "        x = Dropout(rate=hp.Float(f'dropout_{i+1}', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    output_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output')(x)\n",
    "    output_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output')(x)\n",
    "    output_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[output_valence, output_energy, output_danceability])\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'valence_output': 'categorical_crossentropy', \n",
    "                        'energy_output': 'categorical_crossentropy', \n",
    "                        'danceability_output': 'categorical_crossentropy'},\n",
    "                  metrics={'valence_output': 'accuracy', \n",
    "                           'energy_output': 'accuracy', \n",
    "                           'danceability_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# 超参数调优\n",
    "tuner = RandomSearch(\n",
    "    build_cnn_model,\n",
    "    objective=Objective('val_valence_output_accuracy', direction='max'),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='cnn_mood_detection_600'\n",
    ")\n",
    "\n",
    "# 启动调优过程\n",
    "tuner.search(X_train, [y_train_valence, y_train_energy, y_train_danceability], \n",
    "             epochs=20, \n",
    "             validation_data=(X_val, [y_val_valence, y_val_energy, y_val_danceability]), \n",
    "             callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# 评估模型\n",
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = best_model.evaluate(X_test, [y_test_valence, y_test_energy, y_test_danceability])\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}, Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAM BERT (Untuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 132s 11s/step - loss: 3.6786 - valence_output_loss: 1.1647 - energy_output_loss: 1.1419 - danceability_output_loss: 1.1921 - valence_output_accuracy: 0.3984 - energy_output_accuracy: 0.3880 - danceability_output_accuracy: 0.3880 - val_loss: 3.4046 - val_valence_output_loss: 1.1144 - val_energy_output_loss: 1.0627 - val_danceability_output_loss: 1.0476 - val_valence_output_accuracy: 0.3958 - val_energy_output_accuracy: 0.4375 - val_danceability_output_accuracy: 0.4688\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 133s 11s/step - loss: 3.3643 - valence_output_loss: 1.0852 - energy_output_loss: 1.0507 - danceability_output_loss: 1.0486 - valence_output_accuracy: 0.3906 - energy_output_accuracy: 0.4245 - danceability_output_accuracy: 0.4219 - val_loss: 3.4425 - val_valence_output_loss: 1.0532 - val_energy_output_loss: 1.1282 - val_danceability_output_loss: 1.0814 - val_valence_output_accuracy: 0.4792 - val_energy_output_accuracy: 0.4062 - val_danceability_output_accuracy: 0.4271\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 132s 11s/step - loss: 3.2429 - valence_output_loss: 1.0539 - energy_output_loss: 1.0039 - danceability_output_loss: 1.0054 - valence_output_accuracy: 0.4427 - energy_output_accuracy: 0.4844 - danceability_output_accuracy: 0.4922 - val_loss: 3.2928 - val_valence_output_loss: 1.0374 - val_energy_output_loss: 1.0612 - val_danceability_output_loss: 1.0145 - val_valence_output_accuracy: 0.4271 - val_energy_output_accuracy: 0.3958 - val_danceability_output_accuracy: 0.4688\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 205s 18s/step - loss: 3.0871 - valence_output_loss: 0.9927 - energy_output_loss: 0.9724 - danceability_output_loss: 0.9424 - valence_output_accuracy: 0.4896 - energy_output_accuracy: 0.4870 - danceability_output_accuracy: 0.5573 - val_loss: 3.2657 - val_valence_output_loss: 1.0145 - val_energy_output_loss: 1.0492 - val_danceability_output_loss: 1.0224 - val_valence_output_accuracy: 0.4688 - val_energy_output_accuracy: 0.4896 - val_danceability_output_accuracy: 0.4688\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 136s 11s/step - loss: 2.9475 - valence_output_loss: 0.9369 - energy_output_loss: 0.9474 - danceability_output_loss: 0.8836 - valence_output_accuracy: 0.5286 - energy_output_accuracy: 0.5312 - danceability_output_accuracy: 0.5990 - val_loss: 3.2117 - val_valence_output_loss: 1.0121 - val_energy_output_loss: 1.0348 - val_danceability_output_loss: 0.9852 - val_valence_output_accuracy: 0.4271 - val_energy_output_accuracy: 0.5208 - val_danceability_output_accuracy: 0.5000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 3.1708 - valence_output_loss: 1.0292 - energy_output_loss: 1.0383 - danceability_output_loss: 0.9237 - valence_output_accuracy: 0.4583 - energy_output_accuracy: 0.4667 - danceability_output_accuracy: 0.5667\n",
      "Test Loss: 3.170804738998413, valence_output_loss: 1.0291998386383057, energy_output_loss: 1.0383217334747314, danceability_output_loss: 0.9236698150634766\n",
      "Test Accuracy Valence: 0.4583333432674408, Test Accuracy Energy: 0.46666666865348816, Test Accuracy Danceability: 0.5666666626930237\n"
     ]
    }
   ],
   "source": [
    "# 拆分数据集\n",
    "X_train_val, X_test, y_train_val_valence, y_test_valence, y_train_val_energy, y_test_energy, y_train_val_danceability, y_test_danceability = train_test_split(\n",
    "    data['lyrics'], y_valence, y_energy, y_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train_valence, y_val_valence, y_train_energy, y_val_energy, y_train_danceability, y_val_danceability = train_test_split(\n",
    "    X_train_val, y_train_val_valence, y_train_val_energy, y_train_val_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用 BertTokenizer 和 TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize(sentences, tokenizer, max_len=128):\n",
    "    input_ids, attention_masks = [], []\n",
    "    for sent in sentences:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text=sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids), np.array(attention_masks)\n",
    "\n",
    "max_len = 128\n",
    "\n",
    "X_train_input_ids, X_train_attention_masks = tokenize(X_train, tokenizer, max_len)\n",
    "X_val_input_ids, X_val_attention_masks = tokenize(X_val, tokenizer, max_len)\n",
    "X_test_input_ids, X_test_attention_masks = tokenize(X_test, tokenizer, max_len)\n",
    "\n",
    "# 构建BERT模型\n",
    "def build_bert_model():\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]\n",
    "    cls_token = bert_output[:, 0, :]\n",
    "    \n",
    "    # 添加 Dropout 和 L2 正则化\n",
    "    cls_token = Dropout(0.3)(cls_token)\n",
    "\n",
    "    dense_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[dense_valence, dense_energy, dense_danceability])\n",
    "    return model\n",
    "\n",
    "# 构建并训练模型\n",
    "model = build_bert_model()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# 设置学习率调度器\n",
    "num_train_steps = len(X_train_input_ids) // 16 * 5  # 数据量 / batch_size * epochs\n",
    "num_warmup_steps = num_train_steps // 10  # 通常设置为训练步骤的10%\n",
    "\n",
    "optimizer = Adam(learning_rate=tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=2e-5,\n",
    "    decay_steps=num_train_steps,\n",
    "    end_learning_rate=0.0\n",
    "))\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss={'valence_output': 'categorical_crossentropy', \n",
    "                    'energy_output': 'categorical_crossentropy', \n",
    "                    'danceability_output': 'categorical_crossentropy'},\n",
    "              metrics={'valence_output': 'accuracy', \n",
    "                       'energy_output': 'accuracy', \n",
    "                       'danceability_output': 'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_input_ids, X_train_attention_masks],\n",
    "    {'valence_output': y_train_valence, 'energy_output': y_train_energy, 'danceability_output': y_train_danceability},\n",
    "    validation_data=([X_val_input_ids, X_val_attention_masks], {'valence_output': y_val_valence, 'energy_output': y_val_energy, 'danceability_output': y_val_danceability}),\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "loss, valence_output_loss, energy_output_loss, danceability_output_loss, accuracy_valence, accuracy_energy, accuracy_danceability = model.evaluate(\n",
    "    [X_test_input_ids, X_test_attention_masks], \n",
    "    [y_test_valence, y_test_energy, y_test_danceability]\n",
    ")\n",
    "\n",
    "print(f'Test Loss: {loss}, valence_output_loss: {valence_output_loss}, energy_output_loss: {energy_output_loss}, danceability_output_loss: {danceability_output_loss}')\n",
    "print(f'Test Accuracy Valence: {accuracy_valence}, Test Accuracy Energy: {accuracy_energy}, Test Accuracy Danceability: {accuracy_danceability}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have implemented lr and weight decay onto this, therefore it has warm up and decay now with l2 reg, and i only ran 5 epochs because its quite slow on my mac, I noticed the loss is still decreasing drastically, therefore i believe runing more epochs will eventually boost the acc by a lot, can you guys make it 10-15 epochs and test out whats going on at that. Thx, ill now push this version onto github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAM roBERTa (Untuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_3/roberta/pooler/dense/kernel:0', 'tf_roberta_model_3/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_3/roberta/pooler/dense/kernel:0', 'tf_roberta_model_3/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 88\u001b[0m\n\u001b[1;32m     74\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(learning_rate\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mschedules\u001b[38;5;241m.\u001b[39mPolynomialDecay(\n\u001b[1;32m     75\u001b[0m     initial_learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[1;32m     76\u001b[0m     decay_steps\u001b[38;5;241m=\u001b[39mnum_train_steps,\n\u001b[1;32m     77\u001b[0m     end_learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     78\u001b[0m ))\n\u001b[1;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     81\u001b[0m               loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalence_output\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     82\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_output\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_output\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     86\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdanceability_output\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m---> 88\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_attention_masks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalence_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_valence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menergy_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_energy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdanceability_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_danceability\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_attention_masks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalence_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_valence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menergy_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_energy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdanceability_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_danceability\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:890\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    889\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    891\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    892\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[1;32m    893\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_function_spec  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    894\u001b[0m       \u001b[39m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    895\u001b[0m           args, kwds))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:147\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m--> 147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:398\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[1;32m    396\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[0;32m--> 398\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[1;32m    399\u001b[0m     args, kwargs, func_graph)\n\u001b[1;32m    401\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:305\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[1;32m    304\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 305\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    306\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    307\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    308\u001b[0m         args,\n\u001b[1;32m    309\u001b[0m         kwargs,\n\u001b[1;32m    310\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    311\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[1;32m    312\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    313\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[1;32m    314\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    316\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    317\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    322\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1052\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m   1054\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1055\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1057\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m     42\u001b[0m       original_func,\n\u001b[1;32m     43\u001b[0m       args,\n\u001b[1;32m     44\u001b[0m       kwargs,\n\u001b[1;32m     45\u001b[0m       options\u001b[39m=\u001b[39;49mconverter\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     49\u001b[0m       ))\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/sj/bbq0q5pj2bxbbxmgr78vd61r0000gn/T/__autograph_generated_filekiip5goo.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1322\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[1;32m   1319\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1322\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m   1323\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1324\u001b[0m     outputs,\n\u001b[1;32m   1325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1326\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1327\u001b[0m )\n\u001b[1;32m   1328\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1669\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1672\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1673\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3250\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3248\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   3249\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 3250\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4048\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4046\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4047\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 4048\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1303\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1303\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m   1304\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1084\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1083\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[1;32m   1085\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:598\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    568\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \n\u001b[1;32m    570\u001b[0m \u001b[39m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m \n\u001b[1;32m    597\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_gradients(\n\u001b[1;32m    599\u001b[0m         loss, var_list\u001b[39m=\u001b[39;49mvar_list, grad_loss\u001b[39m=\u001b[39;49mgrad_loss, tape\u001b[39m=\u001b[39;49mtape\n\u001b[1;32m    600\u001b[0m     )\n\u001b[1;32m    601\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:656\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    654\u001b[0m var_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(var_list)\n\u001b[1;32m    655\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/gradients\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 656\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_gradients(\n\u001b[1;32m    657\u001b[0m         tape, loss, var_list, grad_loss\n\u001b[1;32m    658\u001b[0m     )\n\u001b[1;32m    660\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_valid_dtypes(\n\u001b[1;32m    661\u001b[0m     [\n\u001b[1;32m    662\u001b[0m         v\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     ]\n\u001b[1;32m    666\u001b[0m )\n\u001b[1;32m    668\u001b[0m \u001b[39mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:532\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gradients\u001b[39m(\u001b[39mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    531\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m     grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, var_list, grad_loss)\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1063\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1057\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[1;32m   1058\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1059\u001b[0m           output_gradients))\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1061\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1063\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[1;32m   1064\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[1;32m   1065\u001b[0m     flat_targets,\n\u001b[1;32m   1066\u001b[0m     flat_sources,\n\u001b[1;32m   1067\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[1;32m   1068\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[1;32m   1069\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[1;32m   1071\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[1;32m   1072\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:146\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py:1459\u001b[0m, in \u001b[0;36m_RealDivGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1457\u001b[0m sx \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape(x)\n\u001b[1;32m   1458\u001b[0m sy \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape(y)\n\u001b[0;32m-> 1459\u001b[0m rx, ry \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mbroadcast_gradient_args(sx, sy)\n\u001b[1;32m   1460\u001b[0m x \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39mconj(x)\n\u001b[1;32m   1461\u001b[0m y \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39mconj(y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:773\u001b[0m, in \u001b[0;36mbroadcast_gradient_args\u001b[0;34m(s0, s1, name)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m--> 773\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m    774\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mBroadcastGradientArgs\u001b[39;49m\u001b[39m\"\u001b[39;49m, s0\u001b[39m=\u001b[39;49ms0, s1\u001b[39m=\u001b[39;49ms1, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    775\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m    776\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    790\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    791\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[1;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    793\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    794\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    796\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m    797\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m    799\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:3381\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3378\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3379\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3380\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3381\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[1;32m   3382\u001b[0m       node_def,\n\u001b[1;32m   3383\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3384\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   3385\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   3386\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   3387\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   3388\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   3389\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[1;32m   3390\u001b[0m   )\n\u001b[1;32m   3391\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   3392\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1889\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1886\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[1;32m   1888\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 1889\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   1890\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, GraphTensor)\n\u001b[1;32m   1891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1732\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1729\u001b[0m     pywrap_tf_session\u001b[39m.\u001b[39mTF_AddInputList(op_desc,\n\u001b[1;32m   1730\u001b[0m                                       [t\u001b[39m.\u001b[39m_as_tf_output() \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m op_input])\n\u001b[1;32m   1731\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1732\u001b[0m     pywrap_tf_session\u001b[39m.\u001b[39mTF_AddInput(op_desc, op_input\u001b[39m.\u001b[39;49m_as_tf_output())\n\u001b[1;32m   1734\u001b[0m \u001b[39m# Add control inputs\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39mfor\u001b[39;00m control_input \u001b[39min\u001b[39;00m control_inputs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 拆分数据集\n",
    "X_train_val, X_test, y_train_val_valence, y_test_valence, y_train_val_energy, y_test_energy, y_train_val_danceability, y_test_danceability = train_test_split(\n",
    "    data['lyrics'], y_valence, y_energy, y_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train_valence, y_val_valence, y_train_energy, y_val_energy, y_train_danceability, y_val_danceability = train_test_split(\n",
    "    X_train_val, y_train_val_valence, y_train_val_energy, y_train_val_danceability, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用 RobertaTokenizer 和 TFRobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def tokenize(sentences, tokenizer, max_len=128):\n",
    "    input_ids, attention_masks = [], []\n",
    "    for sent in sentences:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text=sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids), np.array(attention_masks)\n",
    "\n",
    "max_len = 128\n",
    "\n",
    "X_train_input_ids, X_train_attention_masks = tokenize(X_train, tokenizer, max_len)\n",
    "X_val_input_ids, X_val_attention_masks = tokenize(X_val, tokenizer, max_len)\n",
    "X_test_input_ids, X_test_attention_masks = tokenize(X_test, tokenizer, max_len)\n",
    "\n",
    "# 构建RoBERTa模型\n",
    "def build_roberta_model():\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    roberta_model = TFRobertaModel.from_pretrained('roberta-base')\n",
    "    roberta_output = roberta_model(input_ids, attention_mask=attention_mask)[0]\n",
    "    cls_token = roberta_output[:, 0, :]\n",
    "    \n",
    "    # 添加 Dropout 和 L2 正则化\n",
    "    cls_token = Dropout(0.3)(cls_token)\n",
    "\n",
    "    dense_valence = Dense(y_valence.shape[1], activation='softmax', name='valence_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_energy = Dense(y_energy.shape[1], activation='softmax', name='energy_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    dense_danceability = Dense(y_danceability.shape[1], activation='softmax', name='danceability_output', kernel_regularizer=tf.keras.regularizers.l2(0.01))(cls_token)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[dense_valence, dense_energy, dense_danceability])\n",
    "    return model\n",
    "\n",
    "# 设置学习率调度器\n",
    "def get_optimizer_and_scheduler(num_train_steps, num_warmup_steps):\n",
    "    optimizer = Adam(learning_rate=2e-5, weight_decay=0.01)\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "    return optimizer, lr_scheduler\n",
    "\n",
    "num_train_steps = len(X_train_input_ids) // 16 * 5  # 数据量 / batch_size * epochs\n",
    "num_warmup_steps = num_train_steps // 10  # 通常设置为训练步骤的10%\n",
    "\n",
    "# 构建并训练BERT模型\n",
    "model = build_roberta_model()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# 设置学习率调度器\n",
    "num_train_steps = len(X_train_input_ids) // 16 * 5  # 数据量 / batch_size * epochs\n",
    "num_warmup_steps = num_train_steps // 10  # 通常设置为训练步骤的10%\n",
    "\n",
    "optimizer = Adam(learning_rate=tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=2e-5,\n",
    "    decay_steps=num_train_steps,\n",
    "    end_learning_rate=0.0\n",
    "))\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss={'valence_output': 'categorical_crossentropy', \n",
    "                    'energy_output': 'categorical_crossentropy', \n",
    "                    'danceability_output': 'categorical_crossentropy'},\n",
    "              metrics={'valence_output': 'accuracy', \n",
    "                       'energy_output': 'accuracy', \n",
    "                       'danceability_output': 'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_input_ids, X_train_attention_masks],\n",
    "    {'valence_output': y_train_valence, 'energy_output': y_train_energy, 'danceability_output': y_train_danceability},\n",
    "    validation_data=([X_val_input_ids, X_val_attention_masks], {'valence_output': y_val_valence, 'energy_output': y_val_energy, 'danceability_output': y_val_danceability}),\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 评估RoBERTa模型\n",
    "roberta_loss, roberta_valence_output_loss, roberta_energy_output_loss, roberta_danceability_output_loss, roberta_accuracy_valence, roberta_accuracy_energy, roberta_accuracy_danceability = model.evaluate(\n",
    "    [X_test_input_ids, X_test_attention_masks], \n",
    "    [y_test_valence, y_test_energy, y_test_danceability]\n",
    ")\n",
    "\n",
    "\n",
    "print(f'Test Loss: {roberta_loss}, valence_output_loss: {roberta_valence_output_loss}, energy_output_loss: {roberta_energy_output_loss}, danceability_output_loss: {roberta_accuracy_valence}')\n",
    "print(f'Test Accuracy Valence: {roberta_accuracy_valence}, Test Accuracy Energy: {roberta_accuracy_energy}, Test Accuracy Danceability: {roberta_accuracy_danceability}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 2s/step - loss: 3.2314 - valence_output_loss: 1.0374 - energy_output_loss: 1.0355 - danceability_output_loss: 0.9788 - valence_output_accuracy: 0.5083 - energy_output_accuracy: 0.4500 - danceability_output_accuracy: 0.5083\n",
      "Test Loss: 3.2314350605010986, valence_output_loss: 1.0374451875686646, energy_output_loss: 1.0355204343795776, danceability_output_loss: 0.5083333253860474\n",
      "Test Accuracy Valence: 0.5083333253860474, Test Accuracy Energy: 0.44999998807907104, Test Accuracy Danceability: 0.5083333253860474\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
